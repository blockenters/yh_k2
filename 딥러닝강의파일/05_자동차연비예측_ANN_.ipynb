{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_자동차연비예측_ANN .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt0BNy8OCIai"
      },
      "source": [
        "### Auto MPG 데이터셋을 사용하여 1970년대 후반과 1980년대 초반의 자동차 연비를 예측하는 모델을 만듭니다. 이 정보에는 실린더 수, 배기량, 마력(horsepower), 공차 중량 같은 속성이 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNUpNJoWB7zd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKPm4mQ6DcSL"
      },
      "source": [
        "# 구글 드라이브 마운트\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDwMXlRPbhSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsZtOg8NCH7q"
      },
      "source": [
        "# Working Directory 설정\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YuKKZX0bhqG"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/kdigital2/deeplearning/data')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhKEaW6jChOq"
      },
      "source": [
        "파일은 auto-mpg.csv 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzRVMCyNCHsi"
      },
      "source": [
        "df = pd.read_csv('auto-mpg.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPk1vfCME1Yj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cff47226-8245-498a-b590-bcefa83f1ddd"
      },
      "source": [
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      mpg  cyl  displ   hp  weight  accel  yr  origin  \\\n",
              "0    18.0    8  307.0  130    3504   12.0  70       1   \n",
              "1    15.0    8  350.0  165    3693   11.5  70       1   \n",
              "2    18.0    8  318.0  150    3436   11.0  70       1   \n",
              "3    16.0    8  304.0  150    3433   12.0  70       1   \n",
              "4    17.0    8  302.0  140    3449   10.5  70       1   \n",
              "..    ...  ...    ...  ...     ...    ...  ..     ...   \n",
              "387  27.0    4  140.0   86    2790   15.6  82       1   \n",
              "388  44.0    4   97.0   52    2130   24.6  82       2   \n",
              "389  32.0    4  135.0   84    2295   11.6  82       1   \n",
              "390  28.0    4  120.0   79    2625   18.6  82       1   \n",
              "391  31.0    4  119.0   82    2720   19.4  82       1   \n",
              "\n",
              "                          name  \n",
              "0    chevrolet chevelle malibu  \n",
              "1            buick skylark 320  \n",
              "2           plymouth satellite  \n",
              "3                amc rebel sst  \n",
              "4                  ford torino  \n",
              "..                         ...  \n",
              "387            ford mustang gl  \n",
              "388                  vw pickup  \n",
              "389              dodge rampage  \n",
              "390                ford ranger  \n",
              "391                 chevy s-10  \n",
              "\n",
              "[392 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-041a4af1-46b4-4d04-9c56-c45e0e4a05de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cyl</th>\n",
              "      <th>displ</th>\n",
              "      <th>hp</th>\n",
              "      <th>weight</th>\n",
              "      <th>accel</th>\n",
              "      <th>yr</th>\n",
              "      <th>origin</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86</td>\n",
              "      <td>2790</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>ford mustang gl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52</td>\n",
              "      <td>2130</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "      <td>vw pickup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84</td>\n",
              "      <td>2295</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>dodge rampage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79</td>\n",
              "      <td>2625</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>ford ranger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82</td>\n",
              "      <td>2720</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>chevy s-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-041a4af1-46b4-4d04-9c56-c45e0e4a05de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-041a4af1-46b4-4d04-9c56-c45e0e4a05de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-041a4af1-46b4-4d04-9c56-c45e0e4a05de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5__OhTvCE1Vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4527cb81-bdf5-456e-8cb6-fe1517aa5286"
      },
      "source": [
        "# 1  빈데이터 확인\n",
        "df.isna().sum()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg       0\n",
              "cyl       0\n",
              "displ     0\n",
              "hp        0\n",
              "weight    0\n",
              "accel     0\n",
              "yr        0\n",
              "origin    0\n",
              "name      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwhcBWs9E1Sj"
      },
      "source": [
        "# 2 빈 데이터 삭제\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEQsx0qXT1Oy"
      },
      "source": [
        "# 3. X , y 셋팅"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTFPGytNbrGw"
      },
      "source": [
        "X = df.iloc[ : , 1 : -2+1  ]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiJQxuSJbq-X"
      },
      "source": [
        "y = df['mpg']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TiMd_QZ6k_9N",
        "outputId": "66af891e-bcbe-44f1-e681-e6cef04b2211"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cyl  displ   hp  weight  accel  yr  origin\n",
              "0    8  307.0  130    3504   12.0  70       1\n",
              "1    8  350.0  165    3693   11.5  70       1\n",
              "2    8  318.0  150    3436   11.0  70       1\n",
              "3    8  304.0  150    3433   12.0  70       1\n",
              "4    8  302.0  140    3449   10.5  70       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cbc22f9-9fe3-45ea-9c03-2e37cc67e9b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cyl</th>\n",
              "      <th>displ</th>\n",
              "      <th>hp</th>\n",
              "      <th>weight</th>\n",
              "      <th>accel</th>\n",
              "      <th>yr</th>\n",
              "      <th>origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cbc22f9-9fe3-45ea-9c03-2e37cc67e9b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7cbc22f9-9fe3-45ea-9c03-2e37cc67e9b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7cbc22f9-9fe3-45ea-9c03-2e37cc67e9b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSOXzBc0CHpq"
      },
      "source": [
        "# 4. 카테고리컬 데이터 처리 \n",
        "# Origin 컬럼은 다음과 같다. (1. American, 2. European,3. Japanese)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3ZUf8W0buPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25111c5c-5377-4388-cad2-9b5e32d0d3c1"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 392 entries, 0 to 391\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   cyl     392 non-null    int64  \n",
            " 1   displ   392 non-null    float64\n",
            " 2   hp      392 non-null    int64  \n",
            " 3   weight  392 non-null    int64  \n",
            " 4   accel   392 non-null    float64\n",
            " 5   yr      392 non-null    int64  \n",
            " 6   origin  392 non-null    int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 21.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH6at5_rbuJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697bca2e-5012-45ca-8613-7e944709ea55"
      },
      "source": [
        "X['origin'].nunique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['origin'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFfaN1anlUyl",
        "outputId": "a4101b63-0873-4678-be5b-464e9ba4e564"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "--FnAELJlcMV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "oSKZ7aKOlb_0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer( [ ('encoder', OneHotEncoder(), [6]) ] ,\n",
        "                       remainder= 'passthrough')"
      ],
      "metadata": {
        "id": "7W2o8HzXlbrk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = ct.fit_transform(X)"
      ],
      "metadata": {
        "id": "WoBU3y0clp5s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[ : , 1 :  ]"
      ],
      "metadata": {
        "id": "zYgbYxMAmGw0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScknpszNlpqV",
        "outputId": "40619b04-8c6d-43ae-a536-978212213b8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      18.0\n",
              "1      15.0\n",
              "2      18.0\n",
              "3      16.0\n",
              "4      17.0\n",
              "       ... \n",
              "387    27.0\n",
              "388    44.0\n",
              "389    32.0\n",
              "390    28.0\n",
              "391    31.0\n",
              "Name: mpg, Length: 392, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1CuoYsTCHja"
      },
      "source": [
        "# 5. X 만 피처 스케일링 하시오 (차트 확인을 위해, y는 하지 않습니다.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGYf57sUbwIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a327cc31-ee8b-4fd8-ecc3-265d50cb2ea8"
      },
      "source": [
        "X"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0. ,    0. ,    8. , ..., 3504. ,   12. ,   70. ],\n",
              "       [   0. ,    0. ,    8. , ..., 3693. ,   11.5,   70. ],\n",
              "       [   0. ,    0. ,    8. , ..., 3436. ,   11. ,   70. ],\n",
              "       ...,\n",
              "       [   0. ,    0. ,    4. , ..., 2295. ,   11.6,   82. ],\n",
              "       [   0. ,    0. ,    4. , ..., 2625. ,   18.6,   82. ],\n",
              "       [   0. ,    0. ,    4. , ..., 2720. ,   19.4,   82. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYvwXkODbwFH"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sOTMgt8bwB_"
      },
      "source": [
        "sc_X = MinMaxScaler()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = sc_X.fit_transform(X)"
      ],
      "metadata": {
        "id": "7mrU1P3QnJik"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlLmqK8_CHSL"
      },
      "source": [
        "# 5. 트레인 / 테스트용 셋으로 분리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO9z5bjvb4nL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtB3Y7znb4hd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 7)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gu6ZarpVkjD"
      },
      "source": [
        "# 딥러닝 모델링"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2BlAQYeWCU3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj74iWXRb9iI"
      },
      "source": [
        "# ANN 모델링"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1Sg4WooobXP",
        "outputId": "04eeeda4-d354-4e87-b994-ed1fc96cbd89"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(313, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJKcDp_Lb9dn"
      },
      "source": [
        "def build_model() :\n",
        "  model = Sequential()\n",
        "  model.add( Dense(64, 'relu', input_shape= (8, ) ) )\n",
        "  model.add( Dense(64, 'relu'))\n",
        "  model.add( Dense(1, 'linear'))\n",
        "  # 옵티마이저의 learning rate 을 설정하는 방법 \n",
        "  model.compile(tf.keras.optimizers.RMSprop(learning_rate= 0.001), loss='mse', metrics=['mse', 'mae'])\n",
        "  return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "P4x8MIX3n_Hd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKyphzEsvKTj",
        "outputId": "487937fa-263d-4143-ca3e-fa5da4049976"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 64)                576       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,801\n",
            "Trainable params: 4,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Co1NJMxN2S",
        "outputId": "ccdd46fa-5f6c-487c-d115-548789758bd7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(313, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_history = model.fit(X_train, y_train, epochs = 1000, validation_split= 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRfFZffSvb1b",
        "outputId": "d992f9a5-8b72-4792-bf59-4b38d7d56b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 1s 25ms/step - loss: 598.5978 - mse: 598.5978 - mae: 23.1630 - val_loss: 538.7917 - val_mse: 538.7917 - val_mae: 21.7469\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 566.2003 - mse: 566.2003 - mae: 22.4662 - val_loss: 506.4239 - val_mse: 506.4239 - val_mae: 21.0001\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 529.9188 - mse: 529.9188 - mae: 21.6381 - val_loss: 467.3281 - val_mse: 467.3281 - val_mae: 20.0484\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 486.7387 - mse: 486.7387 - mae: 20.5952 - val_loss: 421.8181 - val_mse: 421.8181 - val_mae: 18.8688\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 436.2948 - mse: 436.2948 - mae: 19.3188 - val_loss: 368.5685 - val_mse: 368.5685 - val_mae: 17.3810\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 378.5686 - mse: 378.5686 - mae: 17.7282 - val_loss: 310.6983 - val_mse: 310.6983 - val_mae: 15.5909\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 317.0865 - mse: 317.0865 - mae: 15.8741 - val_loss: 251.5066 - val_mse: 251.5066 - val_mae: 13.5163\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 255.4686 - mse: 255.4686 - mae: 13.7164 - val_loss: 195.5283 - val_mse: 195.5283 - val_mae: 11.3436\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 199.0346 - mse: 199.0346 - mae: 11.5569 - val_loss: 148.8619 - val_mse: 148.8619 - val_mae: 9.6471\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 151.7078 - mse: 151.7078 - mae: 9.9835 - val_loss: 112.0300 - val_mse: 112.0300 - val_mae: 8.4420\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 115.7404 - mse: 115.7404 - mae: 8.8064 - val_loss: 88.4477 - val_mse: 88.4477 - val_mae: 7.6990\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 92.1562 - mse: 92.1562 - mae: 7.9963 - val_loss: 72.9125 - val_mse: 72.9125 - val_mae: 7.1139\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 75.8651 - mse: 75.8651 - mae: 7.3400 - val_loss: 60.8905 - val_mse: 60.8905 - val_mae: 6.5709\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 63.8107 - mse: 63.8107 - mae: 6.7672 - val_loss: 51.1702 - val_mse: 51.1702 - val_mae: 6.0808\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 54.1346 - mse: 54.1346 - mae: 6.2217 - val_loss: 42.6665 - val_mse: 42.6665 - val_mae: 5.5811\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 46.4008 - mse: 46.4008 - mae: 5.7481 - val_loss: 34.9546 - val_mse: 34.9546 - val_mae: 5.0386\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 39.9299 - mse: 39.9299 - mae: 5.2607 - val_loss: 28.7330 - val_mse: 28.7330 - val_mae: 4.5480\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 34.4332 - mse: 34.4332 - mae: 4.8553 - val_loss: 24.5816 - val_mse: 24.5816 - val_mae: 4.1141\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 31.6384 - mse: 31.6384 - mae: 4.5969 - val_loss: 20.8430 - val_mse: 20.8430 - val_mae: 3.7838\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.7227 - mse: 28.7227 - mae: 4.3353 - val_loss: 18.3603 - val_mse: 18.3603 - val_mae: 3.4980\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.5353 - mse: 26.5353 - mae: 4.1132 - val_loss: 17.1039 - val_mse: 17.1039 - val_mae: 3.3833\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.5681 - mse: 25.5681 - mae: 4.0659 - val_loss: 15.6557 - val_mse: 15.6557 - val_mae: 3.1372\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.2664 - mse: 24.2664 - mae: 3.8876 - val_loss: 15.1457 - val_mse: 15.1457 - val_mae: 3.0371\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.3515 - mse: 23.3515 - mae: 3.7866 - val_loss: 14.6712 - val_mse: 14.6712 - val_mae: 3.0587\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 23.1040 - mse: 23.1040 - mae: 3.8077 - val_loss: 13.9719 - val_mse: 13.9719 - val_mae: 2.9180\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.0296 - mse: 22.0296 - mae: 3.6975 - val_loss: 14.1438 - val_mse: 14.1438 - val_mae: 2.8847\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.8105 - mse: 21.8105 - mae: 3.6005 - val_loss: 13.3514 - val_mse: 13.3514 - val_mae: 2.8498\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.2619 - mse: 21.2619 - mae: 3.6153 - val_loss: 13.2296 - val_mse: 13.2296 - val_mae: 2.8172\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21.1942 - mse: 21.1942 - mae: 3.6053 - val_loss: 12.9181 - val_mse: 12.9181 - val_mae: 2.8257\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 20.0994 - mse: 20.0994 - mae: 3.5281 - val_loss: 12.9575 - val_mse: 12.9575 - val_mae: 2.7722\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.4690 - mse: 19.4690 - mae: 3.4151 - val_loss: 12.6341 - val_mse: 12.6341 - val_mae: 2.7943\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 19.5416 - mse: 19.5416 - mae: 3.4757 - val_loss: 12.0854 - val_mse: 12.0854 - val_mae: 2.7121\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 19.0876 - mse: 19.0876 - mae: 3.4215 - val_loss: 11.8679 - val_mse: 11.8679 - val_mae: 2.7017\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18.6043 - mse: 18.6043 - mae: 3.3911 - val_loss: 11.8831 - val_mse: 11.8831 - val_mae: 2.7126\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 18.0871 - mse: 18.0871 - mae: 3.3390 - val_loss: 11.6194 - val_mse: 11.6194 - val_mae: 2.6889\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 17.8232 - mse: 17.8232 - mae: 3.3189 - val_loss: 11.4213 - val_mse: 11.4213 - val_mae: 2.6583\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 17.6619 - mse: 17.6619 - mae: 3.2896 - val_loss: 11.0361 - val_mse: 11.0361 - val_mae: 2.6313\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.9771 - mse: 16.9771 - mae: 3.2298 - val_loss: 10.8062 - val_mse: 10.8062 - val_mae: 2.6087\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16.8832 - mse: 16.8832 - mae: 3.2169 - val_loss: 10.6230 - val_mse: 10.6230 - val_mae: 2.5889\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 16.2990 - mse: 16.2990 - mae: 3.1259 - val_loss: 10.6594 - val_mse: 10.6594 - val_mae: 2.5737\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16.0777 - mse: 16.0777 - mae: 3.1345 - val_loss: 10.3435 - val_mse: 10.3435 - val_mae: 2.5464\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15.5954 - mse: 15.5954 - mae: 3.0762 - val_loss: 10.2862 - val_mse: 10.2862 - val_mae: 2.5230\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15.9445 - mse: 15.9445 - mae: 3.1370 - val_loss: 9.9243 - val_mse: 9.9243 - val_mae: 2.5100\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.0948 - mse: 15.0948 - mae: 3.0341 - val_loss: 9.7793 - val_mse: 9.7793 - val_mae: 2.4958\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14.9345 - mse: 14.9345 - mae: 3.0121 - val_loss: 9.9498 - val_mse: 9.9498 - val_mae: 2.5233\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.0915 - mse: 15.0915 - mae: 3.0069 - val_loss: 9.5169 - val_mse: 9.5169 - val_mae: 2.4612\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14.3488 - mse: 14.3488 - mae: 2.9411 - val_loss: 9.3886 - val_mse: 9.3886 - val_mae: 2.4389\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14.0820 - mse: 14.0820 - mae: 2.9353 - val_loss: 9.2864 - val_mse: 9.2864 - val_mae: 2.4520\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.9964 - mse: 13.9964 - mae: 2.8997 - val_loss: 9.3859 - val_mse: 9.3859 - val_mae: 2.4103\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.5939 - mse: 13.5939 - mae: 2.8554 - val_loss: 8.9374 - val_mse: 8.9374 - val_mae: 2.3821\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.4826 - mse: 13.4826 - mae: 2.8361 - val_loss: 8.8025 - val_mse: 8.8025 - val_mae: 2.3862\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13.2337 - mse: 13.2337 - mae: 2.8061 - val_loss: 8.6327 - val_mse: 8.6327 - val_mae: 2.3599\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.8221 - mse: 12.8221 - mae: 2.7703 - val_loss: 8.6014 - val_mse: 8.6014 - val_mae: 2.3586\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.5934 - mse: 12.5934 - mae: 2.7567 - val_loss: 8.3431 - val_mse: 8.3431 - val_mae: 2.3116\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.2635 - mse: 12.2635 - mae: 2.6689 - val_loss: 8.2191 - val_mse: 8.2191 - val_mae: 2.2951\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.2393 - mse: 12.2393 - mae: 2.6808 - val_loss: 8.6875 - val_mse: 8.6875 - val_mae: 2.2955\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.0444 - mse: 12.0444 - mae: 2.6417 - val_loss: 8.5660 - val_mse: 8.5660 - val_mae: 2.2804\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.6964 - mse: 11.6964 - mae: 2.6117 - val_loss: 7.7536 - val_mse: 7.7536 - val_mae: 2.2301\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.6416 - mse: 11.6416 - mae: 2.5885 - val_loss: 7.6937 - val_mse: 7.6937 - val_mae: 2.2060\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11.3615 - mse: 11.3615 - mae: 2.5628 - val_loss: 7.5327 - val_mse: 7.5327 - val_mae: 2.1866\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11.6955 - mse: 11.6955 - mae: 2.5970 - val_loss: 7.5510 - val_mse: 7.5510 - val_mae: 2.1749\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.0372 - mse: 11.0372 - mae: 2.5080 - val_loss: 7.3962 - val_mse: 7.3962 - val_mae: 2.1625\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.0571 - mse: 11.0571 - mae: 2.5095 - val_loss: 7.3176 - val_mse: 7.3176 - val_mae: 2.1529\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.8622 - mse: 10.8622 - mae: 2.4800 - val_loss: 7.1732 - val_mse: 7.1732 - val_mae: 2.1147\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.9391 - mse: 10.9391 - mae: 2.4911 - val_loss: 7.2192 - val_mse: 7.2192 - val_mae: 2.1182\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.4651 - mse: 10.4651 - mae: 2.4273 - val_loss: 7.2452 - val_mse: 7.2452 - val_mae: 2.1147\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.2874 - mse: 10.2874 - mae: 2.4023 - val_loss: 7.0100 - val_mse: 7.0100 - val_mae: 2.0832\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.4998 - mse: 10.4998 - mae: 2.4378 - val_loss: 7.2810 - val_mse: 7.2810 - val_mae: 2.1176\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.1965 - mse: 10.1965 - mae: 2.4027 - val_loss: 6.9817 - val_mse: 6.9817 - val_mae: 2.0661\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.9779 - mse: 9.9779 - mae: 2.3614 - val_loss: 6.7582 - val_mse: 6.7582 - val_mae: 2.0273\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.5464 - mse: 9.5464 - mae: 2.3496 - val_loss: 7.9766 - val_mse: 7.9766 - val_mae: 2.2133\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.9651 - mse: 9.9651 - mae: 2.3735 - val_loss: 6.6278 - val_mse: 6.6278 - val_mae: 2.0157\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7555 - mse: 9.7555 - mae: 2.3294 - val_loss: 7.3427 - val_mse: 7.3427 - val_mae: 2.1107\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.9900 - mse: 9.9900 - mae: 2.3532 - val_loss: 6.4849 - val_mse: 6.4849 - val_mae: 1.9775\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.5014 - mse: 9.5014 - mae: 2.2854 - val_loss: 6.3565 - val_mse: 6.3565 - val_mae: 1.9533\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.4546 - mse: 9.4546 - mae: 2.2819 - val_loss: 6.4402 - val_mse: 6.4402 - val_mae: 1.9718\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.4580 - mse: 9.4580 - mae: 2.2907 - val_loss: 7.3633 - val_mse: 7.3633 - val_mae: 2.1207\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.4403 - mse: 9.4403 - mae: 2.2801 - val_loss: 6.4860 - val_mse: 6.4860 - val_mae: 1.9884\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1661 - mse: 9.1661 - mae: 2.2634 - val_loss: 8.1983 - val_mse: 8.1983 - val_mae: 2.2666\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.2087 - mse: 9.2087 - mae: 2.2458 - val_loss: 7.1072 - val_mse: 7.1072 - val_mae: 2.0916\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.3226 - mse: 9.3226 - mae: 2.2834 - val_loss: 6.2257 - val_mse: 6.2257 - val_mae: 1.9299\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.9396 - mse: 8.9396 - mae: 2.2713 - val_loss: 6.6580 - val_mse: 6.6580 - val_mae: 2.0086\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.9992 - mse: 8.9992 - mae: 2.2315 - val_loss: 6.0442 - val_mse: 6.0442 - val_mae: 1.8858\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.0395 - mse: 9.0395 - mae: 2.2232 - val_loss: 6.0254 - val_mse: 6.0254 - val_mae: 1.8786\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7198 - mse: 8.7198 - mae: 2.2215 - val_loss: 6.2758 - val_mse: 6.2758 - val_mae: 1.9624\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8647 - mse: 8.8647 - mae: 2.2311 - val_loss: 6.1021 - val_mse: 6.1021 - val_mae: 1.9341\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.6420 - mse: 8.6420 - mae: 2.1787 - val_loss: 6.3530 - val_mse: 6.3530 - val_mae: 1.9635\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.7509 - mse: 8.7509 - mae: 2.2161 - val_loss: 6.5294 - val_mse: 6.5294 - val_mae: 1.9939\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7332 - mse: 8.7332 - mae: 2.2054 - val_loss: 5.9210 - val_mse: 5.9210 - val_mae: 1.8876\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5597 - mse: 8.5597 - mae: 2.1891 - val_loss: 5.9138 - val_mse: 5.9138 - val_mae: 1.8596\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.7987 - mse: 8.7987 - mae: 2.1770 - val_loss: 6.2562 - val_mse: 6.2562 - val_mae: 1.9486\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.8533 - mse: 8.8533 - mae: 2.2168 - val_loss: 5.7808 - val_mse: 5.7808 - val_mae: 1.8468\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3042 - mse: 8.3042 - mae: 2.1256 - val_loss: 6.2327 - val_mse: 6.2327 - val_mae: 1.9449\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5298 - mse: 8.5298 - mae: 2.1742 - val_loss: 6.0716 - val_mse: 6.0716 - val_mae: 1.8977\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5453 - mse: 8.5453 - mae: 2.1483 - val_loss: 6.1235 - val_mse: 6.1235 - val_mae: 1.9233\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.4250 - mse: 8.4250 - mae: 2.1500 - val_loss: 5.8765 - val_mse: 5.8765 - val_mae: 1.8899\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2907 - mse: 8.2907 - mae: 2.1457 - val_loss: 5.7701 - val_mse: 5.7701 - val_mae: 1.8642\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5009 - mse: 8.5009 - mae: 2.1607 - val_loss: 6.0445 - val_mse: 6.0445 - val_mae: 1.9330\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3273 - mse: 8.3273 - mae: 2.1800 - val_loss: 5.9161 - val_mse: 5.9161 - val_mae: 1.9008\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.1397 - mse: 8.1397 - mae: 2.1240 - val_loss: 5.9390 - val_mse: 5.9390 - val_mae: 1.9110\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2239 - mse: 8.2239 - mae: 2.1446 - val_loss: 5.7985 - val_mse: 5.7985 - val_mae: 1.8638\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4926 - mse: 8.4926 - mae: 2.1546 - val_loss: 5.6001 - val_mse: 5.6001 - val_mae: 1.8298\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.1713 - mse: 8.1713 - mae: 2.1421 - val_loss: 5.5610 - val_mse: 5.5610 - val_mae: 1.8065\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4727 - mse: 8.4727 - mae: 2.1626 - val_loss: 6.3014 - val_mse: 6.3014 - val_mae: 1.9765\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.1089 - mse: 8.1089 - mae: 2.1283 - val_loss: 5.6981 - val_mse: 5.6981 - val_mae: 1.8430\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.0504 - mse: 8.0504 - mae: 2.1138 - val_loss: 5.5544 - val_mse: 5.5544 - val_mae: 1.8197\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.1124 - mse: 8.1124 - mae: 2.1113 - val_loss: 6.8996 - val_mse: 6.8996 - val_mae: 2.0849\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.2698 - mse: 8.2698 - mae: 2.1560 - val_loss: 5.5070 - val_mse: 5.5070 - val_mae: 1.7957\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.0040 - mse: 8.0040 - mae: 2.1226 - val_loss: 5.6064 - val_mse: 5.6064 - val_mae: 1.8245\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.0113 - mse: 8.0113 - mae: 2.0917 - val_loss: 5.5674 - val_mse: 5.5674 - val_mae: 1.8153\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2797 - mse: 8.2797 - mae: 2.1160 - val_loss: 5.5681 - val_mse: 5.5681 - val_mae: 1.8171\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0735 - mse: 8.0735 - mae: 2.1135 - val_loss: 5.7694 - val_mse: 5.7694 - val_mae: 1.8667\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.1636 - mse: 8.1636 - mae: 2.1330 - val_loss: 6.3106 - val_mse: 6.3106 - val_mae: 1.9799\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.0265 - mse: 8.0265 - mae: 2.1010 - val_loss: 7.4459 - val_mse: 7.4459 - val_mae: 2.1741\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0166 - mse: 8.0166 - mae: 2.0893 - val_loss: 6.0976 - val_mse: 6.0976 - val_mae: 1.9514\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9178 - mse: 7.9178 - mae: 2.0964 - val_loss: 5.6927 - val_mse: 5.6927 - val_mae: 1.8586\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0765 - mse: 8.0765 - mae: 2.0858 - val_loss: 6.2287 - val_mse: 6.2287 - val_mae: 1.9668\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9660 - mse: 7.9660 - mae: 2.1087 - val_loss: 5.6395 - val_mse: 5.6395 - val_mae: 1.8522\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9926 - mse: 7.9926 - mae: 2.0927 - val_loss: 6.0544 - val_mse: 6.0544 - val_mae: 1.9376\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9094 - mse: 7.9094 - mae: 2.0844 - val_loss: 6.4392 - val_mse: 6.4392 - val_mae: 1.9997\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.8323 - mse: 7.8323 - mae: 2.0574 - val_loss: 5.4415 - val_mse: 5.4415 - val_mae: 1.8042\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9306 - mse: 7.9306 - mae: 2.0825 - val_loss: 6.8006 - val_mse: 6.8006 - val_mae: 2.0633\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9583 - mse: 7.9583 - mae: 2.1040 - val_loss: 5.8422 - val_mse: 5.8422 - val_mae: 1.8843\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7699 - mse: 7.7699 - mae: 2.1000 - val_loss: 5.9737 - val_mse: 5.9737 - val_mae: 1.9105\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9650 - mse: 7.9650 - mae: 2.1016 - val_loss: 5.4662 - val_mse: 5.4662 - val_mae: 1.8125\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0416 - mse: 8.0416 - mae: 2.0920 - val_loss: 5.5554 - val_mse: 5.5554 - val_mae: 1.8384\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7576 - mse: 7.7576 - mae: 2.0558 - val_loss: 6.7038 - val_mse: 6.7038 - val_mae: 2.0481\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.9469 - mse: 7.9469 - mae: 2.1239 - val_loss: 5.4782 - val_mse: 5.4782 - val_mae: 1.8303\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7637 - mse: 7.7637 - mae: 2.0616 - val_loss: 6.5288 - val_mse: 6.5288 - val_mae: 2.0121\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8376 - mse: 7.8376 - mae: 2.0717 - val_loss: 6.0283 - val_mse: 6.0283 - val_mae: 1.9247\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8598 - mse: 7.8598 - mae: 2.0926 - val_loss: 5.4870 - val_mse: 5.4870 - val_mae: 1.8331\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5017 - mse: 7.5017 - mae: 2.0673 - val_loss: 6.0400 - val_mse: 6.0400 - val_mae: 1.9083\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2046 - mse: 8.2046 - mae: 2.1157 - val_loss: 5.4260 - val_mse: 5.4260 - val_mae: 1.8123\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6947 - mse: 7.6947 - mae: 2.0565 - val_loss: 5.8984 - val_mse: 5.8984 - val_mae: 1.9044\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.6716 - mse: 7.6716 - mae: 2.0800 - val_loss: 5.4551 - val_mse: 5.4551 - val_mae: 1.8221\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7793 - mse: 7.7793 - mae: 2.0743 - val_loss: 5.7383 - val_mse: 5.7383 - val_mae: 1.8761\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9356 - mse: 7.9356 - mae: 2.0903 - val_loss: 5.6289 - val_mse: 5.6289 - val_mae: 1.8555\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6530 - mse: 7.6530 - mae: 2.0567 - val_loss: 5.7121 - val_mse: 5.7121 - val_mae: 1.8746\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8501 - mse: 7.8501 - mae: 2.0982 - val_loss: 5.9015 - val_mse: 5.9015 - val_mae: 1.8996\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8900 - mse: 7.8900 - mae: 2.0938 - val_loss: 5.4943 - val_mse: 5.4943 - val_mae: 1.8380\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7433 - mse: 7.7433 - mae: 2.0925 - val_loss: 5.3392 - val_mse: 5.3392 - val_mae: 1.8050\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8136 - mse: 7.8136 - mae: 2.1224 - val_loss: 5.4010 - val_mse: 5.4010 - val_mae: 1.8163\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.7279 - mse: 7.7279 - mae: 2.0903 - val_loss: 5.3726 - val_mse: 5.3726 - val_mae: 1.8104\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6512 - mse: 7.6512 - mae: 2.0630 - val_loss: 5.3619 - val_mse: 5.3619 - val_mae: 1.8059\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6357 - mse: 7.6357 - mae: 2.0729 - val_loss: 5.3842 - val_mse: 5.3842 - val_mae: 1.7960\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6673 - mse: 7.6673 - mae: 2.0688 - val_loss: 6.0599 - val_mse: 6.0599 - val_mae: 1.9278\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8793 - mse: 7.8793 - mae: 2.0392 - val_loss: 5.8627 - val_mse: 5.8627 - val_mae: 1.8965\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6014 - mse: 7.6014 - mae: 2.0686 - val_loss: 6.9214 - val_mse: 6.9214 - val_mae: 2.0767\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9192 - mse: 7.9192 - mae: 2.0934 - val_loss: 5.6714 - val_mse: 5.6714 - val_mae: 1.8664\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9265 - mse: 7.9265 - mae: 2.0869 - val_loss: 6.5639 - val_mse: 6.5639 - val_mae: 2.0121\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5654 - mse: 7.5654 - mae: 2.0603 - val_loss: 5.2600 - val_mse: 5.2600 - val_mae: 1.7822\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5536 - mse: 7.5536 - mae: 2.0482 - val_loss: 5.9077 - val_mse: 5.9077 - val_mae: 1.9020\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5930 - mse: 7.5930 - mae: 2.0750 - val_loss: 6.3741 - val_mse: 6.3741 - val_mae: 1.9805\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6604 - mse: 7.6604 - mae: 2.0407 - val_loss: 5.3426 - val_mse: 5.3426 - val_mae: 1.8082\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5439 - mse: 7.5439 - mae: 2.0508 - val_loss: 7.0850 - val_mse: 7.0850 - val_mae: 2.1059\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6554 - mse: 7.6554 - mae: 2.0801 - val_loss: 5.4089 - val_mse: 5.4089 - val_mae: 1.8406\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8081 - mse: 7.8081 - mae: 2.1002 - val_loss: 6.0898 - val_mse: 6.0898 - val_mae: 1.9320\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6179 - mse: 7.6179 - mae: 2.0669 - val_loss: 5.9642 - val_mse: 5.9642 - val_mae: 1.9104\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.3604 - mse: 7.3604 - mae: 2.0268 - val_loss: 7.6389 - val_mse: 7.6389 - val_mae: 2.1911\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6883 - mse: 7.6883 - mae: 2.0986 - val_loss: 5.5090 - val_mse: 5.5090 - val_mae: 1.8488\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6428 - mse: 7.6428 - mae: 2.0479 - val_loss: 5.5145 - val_mse: 5.5145 - val_mae: 1.8463\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.6267 - mse: 7.6267 - mae: 2.0720 - val_loss: 5.8272 - val_mse: 5.8272 - val_mae: 1.8965\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7301 - mse: 7.7301 - mae: 2.0858 - val_loss: 5.5086 - val_mse: 5.5086 - val_mae: 1.8393\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4269 - mse: 7.4269 - mae: 2.0209 - val_loss: 5.5662 - val_mse: 5.5662 - val_mae: 1.8470\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.4341 - mse: 7.4341 - mae: 2.0242 - val_loss: 5.9505 - val_mse: 5.9505 - val_mae: 1.9080\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5304 - mse: 7.5304 - mae: 2.0405 - val_loss: 6.7512 - val_mse: 6.7512 - val_mae: 2.0456\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.7369 - mse: 7.7369 - mae: 2.0907 - val_loss: 6.0355 - val_mse: 6.0355 - val_mae: 1.9189\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5774 - mse: 7.5774 - mae: 2.0789 - val_loss: 5.3585 - val_mse: 5.3585 - val_mae: 1.8089\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4771 - mse: 7.4771 - mae: 2.0492 - val_loss: 5.6713 - val_mse: 5.6713 - val_mae: 1.8603\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6007 - mse: 7.6007 - mae: 2.0323 - val_loss: 5.5429 - val_mse: 5.5429 - val_mae: 1.8482\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4364 - mse: 7.4364 - mae: 2.0553 - val_loss: 5.2653 - val_mse: 5.2653 - val_mae: 1.8016\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7010 - mse: 7.7010 - mae: 2.0737 - val_loss: 5.8540 - val_mse: 5.8540 - val_mae: 1.8939\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4241 - mse: 7.4241 - mae: 2.0366 - val_loss: 5.8155 - val_mse: 5.8155 - val_mae: 1.8939\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7921 - mse: 7.7921 - mae: 2.0967 - val_loss: 5.3258 - val_mse: 5.3258 - val_mae: 1.8114\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4436 - mse: 7.4436 - mae: 2.0285 - val_loss: 6.6499 - val_mse: 6.6499 - val_mae: 2.0284\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5654 - mse: 7.5654 - mae: 2.0551 - val_loss: 5.3712 - val_mse: 5.3712 - val_mae: 1.8201\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3702 - mse: 7.3702 - mae: 2.0105 - val_loss: 5.5714 - val_mse: 5.5714 - val_mae: 1.8437\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7427 - mse: 7.7427 - mae: 2.0960 - val_loss: 5.2797 - val_mse: 5.2797 - val_mae: 1.8071\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.3796 - mse: 7.3796 - mae: 2.0096 - val_loss: 5.6972 - val_mse: 5.6972 - val_mae: 1.8763\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4019 - mse: 7.4019 - mae: 2.0250 - val_loss: 5.6428 - val_mse: 5.6428 - val_mae: 1.8623\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4982 - mse: 7.4982 - mae: 2.0286 - val_loss: 6.3670 - val_mse: 6.3670 - val_mae: 1.9756\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3615 - mse: 7.3615 - mae: 2.0338 - val_loss: 7.6572 - val_mse: 7.6572 - val_mae: 2.1854\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5402 - mse: 7.5402 - mae: 2.0556 - val_loss: 5.2795 - val_mse: 5.2795 - val_mae: 1.8303\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5030 - mse: 7.5030 - mae: 2.0609 - val_loss: 5.3625 - val_mse: 5.3625 - val_mae: 1.8310\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.3805 - mse: 7.3805 - mae: 2.0402 - val_loss: 5.4769 - val_mse: 5.4769 - val_mae: 1.8362\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3974 - mse: 7.3974 - mae: 2.0322 - val_loss: 5.6557 - val_mse: 5.6557 - val_mae: 1.8634\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3719 - mse: 7.3719 - mae: 2.0052 - val_loss: 7.0347 - val_mse: 7.0347 - val_mae: 2.0947\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4967 - mse: 7.4967 - mae: 2.0489 - val_loss: 5.3327 - val_mse: 5.3327 - val_mae: 1.8165\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5079 - mse: 7.5079 - mae: 2.0225 - val_loss: 5.3921 - val_mse: 5.3921 - val_mae: 1.8304\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3715 - mse: 7.3715 - mae: 2.0291 - val_loss: 5.2372 - val_mse: 5.2372 - val_mae: 1.8102\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4618 - mse: 7.4618 - mae: 2.0149 - val_loss: 5.2359 - val_mse: 5.2359 - val_mae: 1.8213\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3508 - mse: 7.3508 - mae: 2.0274 - val_loss: 5.3653 - val_mse: 5.3653 - val_mae: 1.8206\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5908 - mse: 7.5908 - mae: 2.0359 - val_loss: 5.2839 - val_mse: 5.2839 - val_mae: 1.8107\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.5176 - mse: 7.5176 - mae: 2.0002 - val_loss: 5.2019 - val_mse: 5.2019 - val_mae: 1.8044\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6800 - mse: 7.6800 - mae: 2.0535 - val_loss: 6.2917 - val_mse: 6.2917 - val_mae: 1.9656\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3601 - mse: 7.3601 - mae: 2.0094 - val_loss: 5.2734 - val_mse: 5.2734 - val_mae: 1.8256\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2671 - mse: 7.2671 - mae: 2.0214 - val_loss: 5.2528 - val_mse: 5.2528 - val_mae: 1.8261\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.4890 - mse: 7.4890 - mae: 2.0213 - val_loss: 5.3807 - val_mse: 5.3807 - val_mae: 1.8199\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7528 - mse: 7.7528 - mae: 2.0806 - val_loss: 5.2174 - val_mse: 5.2174 - val_mae: 1.8016\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2544 - mse: 7.2544 - mae: 2.0090 - val_loss: 5.6262 - val_mse: 5.6262 - val_mae: 1.8570\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3382 - mse: 7.3382 - mae: 2.0375 - val_loss: 5.1778 - val_mse: 5.1778 - val_mae: 1.7779\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4220 - mse: 7.4220 - mae: 2.0298 - val_loss: 5.2342 - val_mse: 5.2342 - val_mae: 1.8093\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3260 - mse: 7.3260 - mae: 2.0159 - val_loss: 5.7450 - val_mse: 5.7450 - val_mae: 1.8806\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2671 - mse: 7.2671 - mae: 2.0119 - val_loss: 5.7229 - val_mse: 5.7229 - val_mae: 1.8952\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2638 - mse: 7.2638 - mae: 2.0366 - val_loss: 5.3395 - val_mse: 5.3395 - val_mae: 1.8289\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3868 - mse: 7.3868 - mae: 2.0425 - val_loss: 6.2018 - val_mse: 6.2018 - val_mae: 1.9489\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4552 - mse: 7.4552 - mae: 2.0517 - val_loss: 5.3838 - val_mse: 5.3838 - val_mae: 1.8292\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4605 - mse: 7.4605 - mae: 2.0190 - val_loss: 5.2001 - val_mse: 5.2001 - val_mae: 1.8020\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2876 - mse: 7.2876 - mae: 1.9947 - val_loss: 5.2694 - val_mse: 5.2694 - val_mae: 1.8065\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3205 - mse: 7.3205 - mae: 1.9971 - val_loss: 5.2807 - val_mse: 5.2807 - val_mae: 1.8037\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2657 - mse: 7.2657 - mae: 2.0236 - val_loss: 5.5188 - val_mse: 5.5188 - val_mae: 1.8316\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1736 - mse: 7.1736 - mae: 1.9903 - val_loss: 5.2042 - val_mse: 5.2042 - val_mae: 1.7980\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5233 - mse: 7.5233 - mae: 2.0474 - val_loss: 5.2157 - val_mse: 5.2157 - val_mae: 1.7713\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3461 - mse: 7.3461 - mae: 2.0071 - val_loss: 5.9976 - val_mse: 5.9976 - val_mae: 1.9180\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3375 - mse: 7.3375 - mae: 2.0079 - val_loss: 6.6305 - val_mse: 6.6305 - val_mae: 2.0194\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4979 - mse: 7.4979 - mae: 2.0378 - val_loss: 5.3683 - val_mse: 5.3683 - val_mae: 1.8347\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.4584 - mse: 7.4584 - mae: 2.0317 - val_loss: 5.2281 - val_mse: 5.2281 - val_mae: 1.8172\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1492 - mse: 7.1492 - mae: 2.0007 - val_loss: 6.2311 - val_mse: 6.2311 - val_mae: 1.9549\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2406 - mse: 7.2406 - mae: 2.0034 - val_loss: 5.7288 - val_mse: 5.7288 - val_mae: 1.8899\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2778 - mse: 7.2778 - mae: 1.9994 - val_loss: 5.3927 - val_mse: 5.3927 - val_mae: 1.8402\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4671 - mse: 7.4671 - mae: 2.0449 - val_loss: 5.7478 - val_mse: 5.7478 - val_mae: 1.8813\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1079 - mse: 7.1079 - mae: 1.9756 - val_loss: 6.0285 - val_mse: 6.0285 - val_mae: 1.9208\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4056 - mse: 7.4056 - mae: 2.0458 - val_loss: 5.5051 - val_mse: 5.5051 - val_mae: 1.8379\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.1103 - mse: 7.1103 - mae: 1.9824 - val_loss: 5.4864 - val_mse: 5.4864 - val_mae: 1.8298\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4932 - mse: 7.4932 - mae: 2.0429 - val_loss: 5.1573 - val_mse: 5.1573 - val_mae: 1.7827\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1896 - mse: 7.1896 - mae: 1.9849 - val_loss: 5.8078 - val_mse: 5.8078 - val_mae: 1.8805\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1905 - mse: 7.1905 - mae: 1.9911 - val_loss: 5.7296 - val_mse: 5.7296 - val_mae: 1.8678\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2636 - mse: 7.2636 - mae: 2.0022 - val_loss: 5.1620 - val_mse: 5.1620 - val_mae: 1.8004\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3270 - mse: 7.3270 - mae: 2.0132 - val_loss: 6.6431 - val_mse: 6.6431 - val_mae: 2.0192\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2501 - mse: 7.2501 - mae: 1.9948 - val_loss: 5.2174 - val_mse: 5.2174 - val_mae: 1.8193\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1349 - mse: 7.1349 - mae: 1.9916 - val_loss: 5.2466 - val_mse: 5.2466 - val_mae: 1.8049\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3202 - mse: 7.3202 - mae: 1.9992 - val_loss: 5.1144 - val_mse: 5.1144 - val_mae: 1.7808\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1552 - mse: 7.1552 - mae: 1.9914 - val_loss: 5.2992 - val_mse: 5.2992 - val_mae: 1.7942\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3954 - mse: 7.3954 - mae: 2.0323 - val_loss: 5.1488 - val_mse: 5.1488 - val_mae: 1.8079\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.1462 - mse: 7.1462 - mae: 1.9941 - val_loss: 5.5605 - val_mse: 5.5605 - val_mae: 1.8512\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.2594 - mse: 7.2594 - mae: 2.0103 - val_loss: 5.3057 - val_mse: 5.3057 - val_mae: 1.8368\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4764 - mse: 7.4764 - mae: 2.0340 - val_loss: 5.3698 - val_mse: 5.3698 - val_mae: 1.8449\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1687 - mse: 7.1687 - mae: 1.9897 - val_loss: 5.2186 - val_mse: 5.2186 - val_mae: 1.8090\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.5793 - mse: 7.5793 - mae: 2.0246 - val_loss: 5.2478 - val_mse: 5.2478 - val_mae: 1.8086\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.2474 - mse: 7.2474 - mae: 1.9877 - val_loss: 5.1592 - val_mse: 5.1592 - val_mae: 1.8026\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3793 - mse: 7.3793 - mae: 2.0133 - val_loss: 5.7840 - val_mse: 5.7840 - val_mae: 1.8847\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2319 - mse: 7.2319 - mae: 1.9984 - val_loss: 5.6599 - val_mse: 5.6599 - val_mae: 1.8578\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1777 - mse: 7.1777 - mae: 1.9948 - val_loss: 5.1702 - val_mse: 5.1702 - val_mae: 1.8101\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3251 - mse: 7.3251 - mae: 2.0236 - val_loss: 5.1808 - val_mse: 5.1808 - val_mae: 1.7897\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1797 - mse: 7.1797 - mae: 1.9984 - val_loss: 5.1344 - val_mse: 5.1344 - val_mae: 1.7930\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0559 - mse: 7.0559 - mae: 1.9846 - val_loss: 5.1483 - val_mse: 5.1483 - val_mae: 1.8013\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.2093 - mse: 7.2093 - mae: 1.9999 - val_loss: 5.2444 - val_mse: 5.2444 - val_mae: 1.8378\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3775 - mse: 7.3775 - mae: 2.0436 - val_loss: 5.1879 - val_mse: 5.1879 - val_mae: 1.8186\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4377 - mse: 7.4377 - mae: 2.0385 - val_loss: 5.0787 - val_mse: 5.0787 - val_mae: 1.7739\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2111 - mse: 7.2111 - mae: 2.0106 - val_loss: 5.0838 - val_mse: 5.0838 - val_mae: 1.7770\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0808 - mse: 7.0808 - mae: 1.9665 - val_loss: 5.1343 - val_mse: 5.1343 - val_mae: 1.8005\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1009 - mse: 7.1009 - mae: 1.9701 - val_loss: 5.3068 - val_mse: 5.3068 - val_mae: 1.8201\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.4332 - mse: 7.4332 - mae: 2.0049 - val_loss: 5.4240 - val_mse: 5.4240 - val_mae: 1.8312\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1505 - mse: 7.1505 - mae: 1.9950 - val_loss: 5.0848 - val_mse: 5.0848 - val_mae: 1.7940\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0412 - mse: 7.0412 - mae: 1.9671 - val_loss: 5.8412 - val_mse: 5.8412 - val_mae: 1.8894\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2563 - mse: 7.2563 - mae: 1.9915 - val_loss: 5.3983 - val_mse: 5.3983 - val_mae: 1.8290\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0688 - mse: 7.0688 - mae: 1.9595 - val_loss: 5.9471 - val_mse: 5.9471 - val_mae: 1.9077\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0889 - mse: 7.0889 - mae: 1.9643 - val_loss: 5.5447 - val_mse: 5.5447 - val_mae: 1.8424\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1855 - mse: 7.1855 - mae: 1.9850 - val_loss: 5.1115 - val_mse: 5.1115 - val_mae: 1.7731\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.0752 - mse: 7.0752 - mae: 1.9479 - val_loss: 5.2477 - val_mse: 5.2477 - val_mae: 1.8266\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0932 - mse: 7.0932 - mae: 1.9799 - val_loss: 5.5822 - val_mse: 5.5822 - val_mae: 1.8625\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0591 - mse: 7.0591 - mae: 1.9793 - val_loss: 5.1307 - val_mse: 5.1307 - val_mae: 1.7934\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1942 - mse: 7.1942 - mae: 1.9763 - val_loss: 5.9209 - val_mse: 5.9209 - val_mae: 1.9013\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2754 - mse: 7.2754 - mae: 2.0037 - val_loss: 5.0784 - val_mse: 5.0784 - val_mae: 1.7936\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1726 - mse: 7.1726 - mae: 1.9896 - val_loss: 5.1174 - val_mse: 5.1174 - val_mae: 1.7718\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0781 - mse: 7.0781 - mae: 1.9500 - val_loss: 6.9951 - val_mse: 6.9951 - val_mae: 2.0827\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0529 - mse: 7.0529 - mae: 1.9882 - val_loss: 5.1060 - val_mse: 5.1060 - val_mae: 1.8039\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3216 - mse: 7.3216 - mae: 2.0051 - val_loss: 5.9721 - val_mse: 5.9721 - val_mae: 1.9116\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9966 - mse: 6.9966 - mae: 1.9643 - val_loss: 5.6897 - val_mse: 5.6897 - val_mae: 1.8610\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0407 - mse: 7.0407 - mae: 1.9793 - val_loss: 6.1934 - val_mse: 6.1934 - val_mae: 1.9448\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.2158 - mse: 7.2158 - mae: 1.9858 - val_loss: 5.5750 - val_mse: 5.5750 - val_mae: 1.8517\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0010 - mse: 7.0010 - mae: 1.9607 - val_loss: 5.0717 - val_mse: 5.0717 - val_mae: 1.7820\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1505 - mse: 7.1505 - mae: 1.9862 - val_loss: 5.2125 - val_mse: 5.2125 - val_mae: 1.7938\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1386 - mse: 7.1386 - mae: 1.9628 - val_loss: 5.5423 - val_mse: 5.5423 - val_mae: 1.8416\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0833 - mse: 7.0833 - mae: 1.9548 - val_loss: 6.1124 - val_mse: 6.1124 - val_mae: 1.9319\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0287 - mse: 7.0287 - mae: 1.9618 - val_loss: 5.0389 - val_mse: 5.0389 - val_mae: 1.7812\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1659 - mse: 7.1659 - mae: 2.0129 - val_loss: 5.1369 - val_mse: 5.1369 - val_mae: 1.7849\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0576 - mse: 7.0576 - mae: 1.9877 - val_loss: 5.3148 - val_mse: 5.3148 - val_mae: 1.8102\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3333 - mse: 7.3333 - mae: 1.9960 - val_loss: 5.0158 - val_mse: 5.0158 - val_mae: 1.7630\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9880 - mse: 6.9880 - mae: 1.9492 - val_loss: 5.4349 - val_mse: 5.4349 - val_mae: 1.8212\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9609 - mse: 6.9609 - mae: 1.9462 - val_loss: 5.4510 - val_mse: 5.4510 - val_mae: 1.8259\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1616 - mse: 7.1616 - mae: 1.9559 - val_loss: 5.0991 - val_mse: 5.0991 - val_mae: 1.7810\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0588 - mse: 7.0588 - mae: 1.9857 - val_loss: 5.4710 - val_mse: 5.4710 - val_mae: 1.8275\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9963 - mse: 6.9963 - mae: 1.9558 - val_loss: 5.4064 - val_mse: 5.4064 - val_mae: 1.8214\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0668 - mse: 7.0668 - mae: 1.9887 - val_loss: 5.7136 - val_mse: 5.7136 - val_mae: 1.8717\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0971 - mse: 7.0971 - mae: 1.9525 - val_loss: 4.9961 - val_mse: 4.9961 - val_mae: 1.7829\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0006 - mse: 7.0006 - mae: 1.9459 - val_loss: 6.2195 - val_mse: 6.2195 - val_mae: 1.9528\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1194 - mse: 7.1194 - mae: 1.9667 - val_loss: 5.4168 - val_mse: 5.4168 - val_mae: 1.8354\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0519 - mse: 7.0519 - mae: 1.9692 - val_loss: 5.0650 - val_mse: 5.0650 - val_mae: 1.7830\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0411 - mse: 7.0411 - mae: 1.9691 - val_loss: 5.1269 - val_mse: 5.1269 - val_mae: 1.7907\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9888 - mse: 6.9888 - mae: 1.9932 - val_loss: 5.2136 - val_mse: 5.2136 - val_mae: 1.8021\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0057 - mse: 7.0057 - mae: 1.9315 - val_loss: 5.3093 - val_mse: 5.3093 - val_mae: 1.8186\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0108 - mse: 7.0108 - mae: 1.9615 - val_loss: 6.2904 - val_mse: 6.2904 - val_mae: 1.9587\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0493 - mse: 7.0493 - mae: 1.9596 - val_loss: 6.1668 - val_mse: 6.1668 - val_mae: 1.9412\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1157 - mse: 7.1157 - mae: 1.9725 - val_loss: 5.8780 - val_mse: 5.8780 - val_mae: 1.9008\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0363 - mse: 7.0363 - mae: 1.9576 - val_loss: 5.0534 - val_mse: 5.0534 - val_mae: 1.7881\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0897 - mse: 7.0897 - mae: 1.9723 - val_loss: 5.1685 - val_mse: 5.1685 - val_mae: 1.8053\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0093 - mse: 7.0093 - mae: 1.9452 - val_loss: 5.6249 - val_mse: 5.6249 - val_mae: 1.8622\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9156 - mse: 6.9156 - mae: 1.9439 - val_loss: 5.4047 - val_mse: 5.4047 - val_mae: 1.8271\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2066 - mse: 7.2066 - mae: 2.0061 - val_loss: 5.0750 - val_mse: 5.0750 - val_mae: 1.7869\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9335 - mse: 6.9335 - mae: 1.9599 - val_loss: 5.4074 - val_mse: 5.4074 - val_mae: 1.8381\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8978 - mse: 6.8978 - mae: 1.9261 - val_loss: 5.3989 - val_mse: 5.3989 - val_mae: 1.8352\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0805 - mse: 7.0805 - mae: 1.9714 - val_loss: 6.3702 - val_mse: 6.3702 - val_mae: 1.9781\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.0865 - mse: 7.0865 - mae: 1.9860 - val_loss: 5.0441 - val_mse: 5.0441 - val_mae: 1.7663\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0116 - mse: 7.0116 - mae: 1.9339 - val_loss: 5.2821 - val_mse: 5.2821 - val_mae: 1.8093\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9063 - mse: 6.9063 - mae: 1.9344 - val_loss: 5.1719 - val_mse: 5.1719 - val_mae: 1.7920\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9043 - mse: 6.9043 - mae: 1.9419 - val_loss: 7.1401 - val_mse: 7.1401 - val_mae: 2.1038\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2649 - mse: 7.2649 - mae: 1.9880 - val_loss: 5.0492 - val_mse: 5.0492 - val_mae: 1.7980\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9046 - mse: 6.9046 - mae: 1.9513 - val_loss: 5.0608 - val_mse: 5.0608 - val_mae: 1.7944\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0698 - mse: 7.0698 - mae: 1.9562 - val_loss: 5.1402 - val_mse: 5.1402 - val_mae: 1.7862\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9081 - mse: 6.9081 - mae: 1.9278 - val_loss: 5.1291 - val_mse: 5.1291 - val_mae: 1.8154\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1434 - mse: 7.1434 - mae: 1.9556 - val_loss: 5.1887 - val_mse: 5.1887 - val_mae: 1.8084\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2244 - mse: 7.2244 - mae: 1.9833 - val_loss: 5.1270 - val_mse: 5.1270 - val_mae: 1.8084\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9496 - mse: 6.9496 - mae: 1.9376 - val_loss: 5.0866 - val_mse: 5.0866 - val_mae: 1.8113\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8804 - mse: 6.8804 - mae: 1.9357 - val_loss: 4.8901 - val_mse: 4.8901 - val_mae: 1.7496\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9405 - mse: 6.9405 - mae: 1.9344 - val_loss: 5.0576 - val_mse: 5.0576 - val_mae: 1.7804\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8933 - mse: 6.8933 - mae: 1.9476 - val_loss: 4.9479 - val_mse: 4.9479 - val_mae: 1.7504\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0019 - mse: 7.0019 - mae: 1.9524 - val_loss: 6.3627 - val_mse: 6.3627 - val_mae: 1.9783\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0558 - mse: 7.0558 - mae: 1.9647 - val_loss: 5.1032 - val_mse: 5.1032 - val_mae: 1.7787\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8381 - mse: 6.8381 - mae: 1.9390 - val_loss: 5.0219 - val_mse: 5.0219 - val_mae: 1.7812\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8560 - mse: 6.8560 - mae: 1.9326 - val_loss: 4.9673 - val_mse: 4.9673 - val_mae: 1.7831\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8755 - mse: 6.8755 - mae: 1.9246 - val_loss: 5.2503 - val_mse: 5.2503 - val_mae: 1.8148\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.7723 - mse: 6.7723 - mae: 1.9248 - val_loss: 5.2839 - val_mse: 5.2839 - val_mae: 1.8154\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0154 - mse: 7.0154 - mae: 1.9686 - val_loss: 5.1394 - val_mse: 5.1394 - val_mae: 1.7809\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8292 - mse: 6.8292 - mae: 1.9243 - val_loss: 5.3566 - val_mse: 5.3566 - val_mae: 1.8329\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0813 - mse: 7.0813 - mae: 1.9609 - val_loss: 5.2451 - val_mse: 5.2451 - val_mae: 1.8146\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.9366 - mse: 6.9366 - mae: 1.9605 - val_loss: 5.9368 - val_mse: 5.9368 - val_mae: 1.9088\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9730 - mse: 6.9730 - mae: 1.9539 - val_loss: 4.9793 - val_mse: 4.9793 - val_mae: 1.8015\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9041 - mse: 6.9041 - mae: 1.9266 - val_loss: 5.3894 - val_mse: 5.3894 - val_mae: 1.8282\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9647 - mse: 6.9647 - mae: 1.9525 - val_loss: 5.7837 - val_mse: 5.7837 - val_mae: 1.8930\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9847 - mse: 6.9847 - mae: 1.9392 - val_loss: 4.9872 - val_mse: 4.9872 - val_mae: 1.7902\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8821 - mse: 6.8821 - mae: 1.9127 - val_loss: 5.2750 - val_mse: 5.2750 - val_mae: 1.8119\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7896 - mse: 6.7896 - mae: 1.9447 - val_loss: 5.1911 - val_mse: 5.1911 - val_mae: 1.7942\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.9080 - mse: 6.9080 - mae: 1.9066 - val_loss: 5.0534 - val_mse: 5.0534 - val_mae: 1.7780\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6875 - mse: 6.6875 - mae: 1.9090 - val_loss: 5.0636 - val_mse: 5.0636 - val_mae: 1.7919\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0218 - mse: 7.0218 - mae: 1.9610 - val_loss: 5.2855 - val_mse: 5.2855 - val_mae: 1.8099\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9058 - mse: 6.9058 - mae: 1.9427 - val_loss: 4.8687 - val_mse: 4.8687 - val_mae: 1.7356\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1954 - mse: 7.1954 - mae: 1.9607 - val_loss: 5.0278 - val_mse: 5.0278 - val_mae: 1.7779\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9900 - mse: 6.9900 - mae: 1.9387 - val_loss: 5.0768 - val_mse: 5.0768 - val_mae: 1.7789\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7895 - mse: 6.7895 - mae: 1.9086 - val_loss: 5.1114 - val_mse: 5.1114 - val_mae: 1.7821\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8577 - mse: 6.8577 - mae: 1.9327 - val_loss: 5.1080 - val_mse: 5.1080 - val_mae: 1.7923\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8298 - mse: 6.8298 - mae: 1.9118 - val_loss: 5.0806 - val_mse: 5.0806 - val_mae: 1.7874\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9079 - mse: 6.9079 - mae: 1.9256 - val_loss: 4.8933 - val_mse: 4.8933 - val_mae: 1.7586\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8590 - mse: 6.8590 - mae: 1.9208 - val_loss: 5.2209 - val_mse: 5.2209 - val_mae: 1.8083\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0880 - mse: 7.0880 - mae: 1.9560 - val_loss: 5.4160 - val_mse: 5.4160 - val_mae: 1.8324\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7708 - mse: 6.7708 - mae: 1.8994 - val_loss: 4.9123 - val_mse: 4.9123 - val_mae: 1.7573\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9127 - mse: 6.9127 - mae: 1.9575 - val_loss: 5.1203 - val_mse: 5.1203 - val_mae: 1.7928\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9076 - mse: 6.9076 - mae: 1.9371 - val_loss: 5.6334 - val_mse: 5.6334 - val_mae: 1.8728\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7483 - mse: 6.7483 - mae: 1.9043 - val_loss: 7.6334 - val_mse: 7.6334 - val_mae: 2.1946\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1253 - mse: 7.1253 - mae: 1.9684 - val_loss: 5.2665 - val_mse: 5.2665 - val_mae: 1.8187\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6678 - mse: 6.6678 - mae: 1.8961 - val_loss: 5.3935 - val_mse: 5.3935 - val_mae: 1.8352\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9186 - mse: 6.9186 - mae: 1.9470 - val_loss: 4.9941 - val_mse: 4.9941 - val_mae: 1.7886\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9398 - mse: 6.9398 - mae: 1.9154 - val_loss: 5.0014 - val_mse: 5.0014 - val_mae: 1.7684\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8816 - mse: 6.8816 - mae: 1.9299 - val_loss: 5.8061 - val_mse: 5.8061 - val_mae: 1.8975\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9843 - mse: 6.9843 - mae: 1.9370 - val_loss: 5.1764 - val_mse: 5.1764 - val_mae: 1.7962\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8277 - mse: 6.8277 - mae: 1.9412 - val_loss: 5.0520 - val_mse: 5.0520 - val_mae: 1.7777\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.8199 - mse: 6.8199 - mae: 1.9211 - val_loss: 5.4559 - val_mse: 5.4559 - val_mae: 1.8507\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7867 - mse: 6.7867 - mae: 1.9061 - val_loss: 5.5934 - val_mse: 5.5934 - val_mae: 1.8660\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8630 - mse: 6.8630 - mae: 1.9436 - val_loss: 4.8718 - val_mse: 4.8718 - val_mae: 1.7493\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8625 - mse: 6.8625 - mae: 1.9124 - val_loss: 5.5351 - val_mse: 5.5351 - val_mae: 1.8517\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9529 - mse: 6.9529 - mae: 1.9409 - val_loss: 5.1724 - val_mse: 5.1724 - val_mae: 1.8011\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7633 - mse: 6.7633 - mae: 1.9099 - val_loss: 5.2551 - val_mse: 5.2551 - val_mae: 1.8143\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8126 - mse: 6.8126 - mae: 1.9167 - val_loss: 5.2901 - val_mse: 5.2901 - val_mae: 1.8139\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9309 - mse: 6.9309 - mae: 1.9138 - val_loss: 5.4456 - val_mse: 5.4456 - val_mae: 1.8442\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7725 - mse: 6.7725 - mae: 1.9005 - val_loss: 5.0371 - val_mse: 5.0371 - val_mae: 1.7956\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0409 - mse: 7.0409 - mae: 1.9621 - val_loss: 5.3326 - val_mse: 5.3326 - val_mae: 1.8262\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7496 - mse: 6.7496 - mae: 1.9203 - val_loss: 5.1772 - val_mse: 5.1772 - val_mae: 1.7978\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7379 - mse: 6.7379 - mae: 1.9059 - val_loss: 4.8873 - val_mse: 4.8873 - val_mae: 1.7655\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7000 - mse: 6.7000 - mae: 1.8819 - val_loss: 5.2571 - val_mse: 5.2571 - val_mae: 1.8136\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0166 - mse: 7.0166 - mae: 1.9610 - val_loss: 4.9817 - val_mse: 4.9817 - val_mae: 1.7685\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7433 - mse: 6.7433 - mae: 1.8811 - val_loss: 6.1892 - val_mse: 6.1892 - val_mae: 1.9512\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9784 - mse: 6.9784 - mae: 1.9224 - val_loss: 5.6921 - val_mse: 5.6921 - val_mae: 1.8781\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8001 - mse: 6.8001 - mae: 1.9230 - val_loss: 5.1926 - val_mse: 5.1926 - val_mae: 1.8013\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.3036 - mse: 7.3036 - mae: 1.9427 - val_loss: 4.9434 - val_mse: 4.9434 - val_mae: 1.7633\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.6416 - mse: 6.6416 - mae: 1.8865 - val_loss: 5.1868 - val_mse: 5.1868 - val_mae: 1.8011\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6091 - mse: 6.6091 - mae: 1.8784 - val_loss: 5.1368 - val_mse: 5.1368 - val_mae: 1.7984\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8234 - mse: 6.8234 - mae: 1.9115 - val_loss: 5.5218 - val_mse: 5.5218 - val_mae: 1.8624\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8943 - mse: 6.8943 - mae: 1.9227 - val_loss: 4.8966 - val_mse: 4.8966 - val_mae: 1.7847\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7527 - mse: 6.7527 - mae: 1.8982 - val_loss: 4.8968 - val_mse: 4.8968 - val_mae: 1.7490\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6473 - mse: 6.6473 - mae: 1.8722 - val_loss: 5.1297 - val_mse: 5.1297 - val_mae: 1.7909\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6774 - mse: 6.6774 - mae: 1.8684 - val_loss: 5.5989 - val_mse: 5.5989 - val_mae: 1.8692\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8508 - mse: 6.8508 - mae: 1.9045 - val_loss: 4.9804 - val_mse: 4.9804 - val_mae: 1.7718\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7337 - mse: 6.7337 - mae: 1.8962 - val_loss: 4.8983 - val_mse: 4.8983 - val_mae: 1.7850\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6612 - mse: 6.6612 - mae: 1.9055 - val_loss: 6.2056 - val_mse: 6.2056 - val_mae: 1.9601\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7969 - mse: 6.7969 - mae: 1.9208 - val_loss: 5.6613 - val_mse: 5.6613 - val_mae: 1.8836\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6150 - mse: 6.6150 - mae: 1.8765 - val_loss: 5.4885 - val_mse: 5.4885 - val_mae: 1.8583\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6467 - mse: 6.6467 - mae: 1.8899 - val_loss: 5.0066 - val_mse: 5.0066 - val_mae: 1.7758\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7063 - mse: 6.7063 - mae: 1.8710 - val_loss: 5.0296 - val_mse: 5.0296 - val_mae: 1.7775\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8490 - mse: 6.8490 - mae: 1.9274 - val_loss: 5.2449 - val_mse: 5.2449 - val_mae: 1.8138\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7159 - mse: 6.7159 - mae: 1.8967 - val_loss: 4.8278 - val_mse: 4.8278 - val_mae: 1.7388\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5561 - mse: 6.5561 - mae: 1.8611 - val_loss: 4.7733 - val_mse: 4.7733 - val_mae: 1.7232\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9048 - mse: 6.9048 - mae: 1.9027 - val_loss: 5.2476 - val_mse: 5.2476 - val_mae: 1.8183\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6314 - mse: 6.6314 - mae: 1.9000 - val_loss: 6.1556 - val_mse: 6.1556 - val_mae: 1.9554\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7229 - mse: 6.7229 - mae: 1.8839 - val_loss: 4.8385 - val_mse: 4.8385 - val_mae: 1.7774\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5066 - mse: 6.5066 - mae: 1.8639 - val_loss: 5.3749 - val_mse: 5.3749 - val_mae: 1.8518\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8917 - mse: 6.8917 - mae: 1.9104 - val_loss: 4.8518 - val_mse: 4.8518 - val_mae: 1.7459\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6515 - mse: 6.6515 - mae: 1.8860 - val_loss: 4.7469 - val_mse: 4.7469 - val_mae: 1.7202\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5231 - mse: 6.5231 - mae: 1.8857 - val_loss: 4.7510 - val_mse: 4.7510 - val_mae: 1.7247\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8015 - mse: 6.8015 - mae: 1.9083 - val_loss: 4.7509 - val_mse: 4.7509 - val_mae: 1.7326\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6379 - mse: 6.6379 - mae: 1.8934 - val_loss: 5.3897 - val_mse: 5.3897 - val_mae: 1.8404\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6629 - mse: 6.6629 - mae: 1.8847 - val_loss: 5.1671 - val_mse: 5.1671 - val_mae: 1.8099\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.7185 - mse: 6.7185 - mae: 1.9155 - val_loss: 5.5683 - val_mse: 5.5683 - val_mae: 1.8759\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6827 - mse: 6.6827 - mae: 1.8992 - val_loss: 4.7870 - val_mse: 4.7870 - val_mae: 1.7433\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5918 - mse: 6.5918 - mae: 1.8898 - val_loss: 5.1448 - val_mse: 5.1448 - val_mae: 1.8229\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5181 - mse: 6.5181 - mae: 1.8554 - val_loss: 5.3217 - val_mse: 5.3217 - val_mae: 1.8339\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6835 - mse: 6.6835 - mae: 1.8985 - val_loss: 4.9287 - val_mse: 4.9287 - val_mae: 1.7676\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8239 - mse: 6.8239 - mae: 1.9012 - val_loss: 5.2972 - val_mse: 5.2972 - val_mae: 1.8267\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.4746 - mse: 6.4746 - mae: 1.8926 - val_loss: 4.7575 - val_mse: 4.7575 - val_mae: 1.7276\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.5480 - mse: 6.5480 - mae: 1.8712 - val_loss: 5.5649 - val_mse: 5.5649 - val_mae: 1.8736\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6769 - mse: 6.6769 - mae: 1.8786 - val_loss: 4.7317 - val_mse: 4.7317 - val_mae: 1.7277\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9441 - mse: 6.9441 - mae: 1.9280 - val_loss: 4.6949 - val_mse: 4.6949 - val_mae: 1.7331\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.4091 - mse: 6.4091 - mae: 1.8359 - val_loss: 6.6727 - val_mse: 6.6727 - val_mae: 2.0253\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7415 - mse: 6.7415 - mae: 1.9032 - val_loss: 5.9535 - val_mse: 5.9535 - val_mae: 1.9199\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5987 - mse: 6.5987 - mae: 1.8802 - val_loss: 4.8427 - val_mse: 4.8427 - val_mae: 1.7509\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6682 - mse: 6.6682 - mae: 1.8977 - val_loss: 5.0410 - val_mse: 5.0410 - val_mae: 1.7862\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6485 - mse: 6.6485 - mae: 1.9050 - val_loss: 5.0161 - val_mse: 5.0161 - val_mae: 1.7842\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6682 - mse: 6.6682 - mae: 1.8760 - val_loss: 4.8456 - val_mse: 4.8456 - val_mae: 1.7553\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7818 - mse: 6.7818 - mae: 1.9205 - val_loss: 4.8216 - val_mse: 4.8216 - val_mae: 1.7500\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5591 - mse: 6.5591 - mae: 1.8782 - val_loss: 4.7793 - val_mse: 4.7793 - val_mae: 1.7706\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4913 - mse: 6.4913 - mae: 1.8555 - val_loss: 4.9603 - val_mse: 4.9603 - val_mae: 1.7765\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8326 - mse: 6.8326 - mae: 1.9224 - val_loss: 5.0489 - val_mse: 5.0489 - val_mae: 1.7785\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6536 - mse: 6.6536 - mae: 1.8522 - val_loss: 4.6544 - val_mse: 4.6544 - val_mae: 1.7031\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5870 - mse: 6.5870 - mae: 1.8670 - val_loss: 5.7937 - val_mse: 5.7937 - val_mae: 1.9017\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7380 - mse: 6.7380 - mae: 1.9269 - val_loss: 4.7798 - val_mse: 4.7798 - val_mae: 1.7541\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.4429 - mse: 6.4429 - mae: 1.8498 - val_loss: 4.6616 - val_mse: 4.6616 - val_mae: 1.7197\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6272 - mse: 6.6272 - mae: 1.8570 - val_loss: 5.0943 - val_mse: 5.0943 - val_mae: 1.8017\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5612 - mse: 6.5612 - mae: 1.8755 - val_loss: 4.6661 - val_mse: 4.6661 - val_mae: 1.7192\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7012 - mse: 6.7012 - mae: 1.8767 - val_loss: 5.8043 - val_mse: 5.8043 - val_mae: 1.9010\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6119 - mse: 6.6119 - mae: 1.8715 - val_loss: 5.5468 - val_mse: 5.5468 - val_mae: 1.8678\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5145 - mse: 6.5145 - mae: 1.8607 - val_loss: 4.9077 - val_mse: 4.9077 - val_mae: 1.7714\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4183 - mse: 6.4183 - mae: 1.8340 - val_loss: 5.0264 - val_mse: 5.0264 - val_mae: 1.7881\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4748 - mse: 6.4748 - mae: 1.8474 - val_loss: 5.0525 - val_mse: 5.0525 - val_mae: 1.7902\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3912 - mse: 6.3912 - mae: 1.8521 - val_loss: 4.9643 - val_mse: 4.9643 - val_mae: 1.7791\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5806 - mse: 6.5806 - mae: 1.8978 - val_loss: 4.6517 - val_mse: 4.6517 - val_mae: 1.7199\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5091 - mse: 6.5091 - mae: 1.8396 - val_loss: 5.0064 - val_mse: 5.0064 - val_mae: 1.7863\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7998 - mse: 6.7998 - mae: 1.9270 - val_loss: 4.7832 - val_mse: 4.7832 - val_mae: 1.7420\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4612 - mse: 6.4612 - mae: 1.8552 - val_loss: 6.0032 - val_mse: 6.0032 - val_mae: 1.9400\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5250 - mse: 6.5250 - mae: 1.8720 - val_loss: 4.7718 - val_mse: 4.7718 - val_mae: 1.7567\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5453 - mse: 6.5453 - mae: 1.8539 - val_loss: 4.8134 - val_mse: 4.8134 - val_mae: 1.7641\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7540 - mse: 6.7540 - mae: 1.9018 - val_loss: 4.7403 - val_mse: 4.7403 - val_mae: 1.7603\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6199 - mse: 6.6199 - mae: 1.8935 - val_loss: 4.7345 - val_mse: 4.7345 - val_mae: 1.7391\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3540 - mse: 6.3540 - mae: 1.8520 - val_loss: 5.4869 - val_mse: 5.4869 - val_mae: 1.8638\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.5704 - mse: 6.5704 - mae: 1.8777 - val_loss: 4.6986 - val_mse: 4.6986 - val_mae: 1.7495\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5597 - mse: 6.5597 - mae: 1.8663 - val_loss: 4.8013 - val_mse: 4.8013 - val_mae: 1.7572\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3859 - mse: 6.3859 - mae: 1.8524 - val_loss: 4.7043 - val_mse: 4.7043 - val_mae: 1.7562\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4970 - mse: 6.4970 - mae: 1.8567 - val_loss: 5.3788 - val_mse: 5.3788 - val_mae: 1.8535\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2840 - mse: 6.2840 - mae: 1.8542 - val_loss: 5.8344 - val_mse: 5.8344 - val_mae: 1.9168\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4442 - mse: 6.4442 - mae: 1.8332 - val_loss: 6.2275 - val_mse: 6.2275 - val_mae: 1.9682\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5005 - mse: 6.5005 - mae: 1.8843 - val_loss: 5.0055 - val_mse: 5.0055 - val_mae: 1.7913\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5557 - mse: 6.5557 - mae: 1.8743 - val_loss: 4.6968 - val_mse: 4.6968 - val_mae: 1.7360\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3728 - mse: 6.3728 - mae: 1.8331 - val_loss: 5.9370 - val_mse: 5.9370 - val_mae: 1.9274\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4344 - mse: 6.4344 - mae: 1.8571 - val_loss: 4.8964 - val_mse: 4.8964 - val_mae: 1.7712\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7983 - mse: 6.7983 - mae: 1.9036 - val_loss: 5.1253 - val_mse: 5.1253 - val_mae: 1.8136\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4097 - mse: 6.4097 - mae: 1.8514 - val_loss: 4.7315 - val_mse: 4.7315 - val_mae: 1.7563\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4309 - mse: 6.4309 - mae: 1.8411 - val_loss: 4.8731 - val_mse: 4.8731 - val_mae: 1.7634\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3878 - mse: 6.3878 - mae: 1.8396 - val_loss: 4.9250 - val_mse: 4.9250 - val_mae: 1.7761\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3754 - mse: 6.3754 - mae: 1.8147 - val_loss: 4.6751 - val_mse: 4.6751 - val_mae: 1.7303\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6031 - mse: 6.6031 - mae: 1.9085 - val_loss: 4.6271 - val_mse: 4.6271 - val_mae: 1.7070\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3915 - mse: 6.3915 - mae: 1.8373 - val_loss: 4.6274 - val_mse: 4.6274 - val_mae: 1.7093\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3284 - mse: 6.3284 - mae: 1.8282 - val_loss: 6.4346 - val_mse: 6.4346 - val_mae: 1.9971\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7783 - mse: 6.7783 - mae: 1.8782 - val_loss: 5.3136 - val_mse: 5.3136 - val_mae: 1.8348\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3512 - mse: 6.3512 - mae: 1.8376 - val_loss: 5.4806 - val_mse: 5.4806 - val_mae: 1.8613\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4373 - mse: 6.4373 - mae: 1.8637 - val_loss: 5.6905 - val_mse: 5.6905 - val_mae: 1.8927\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6697 - mse: 6.6697 - mae: 1.8938 - val_loss: 5.1705 - val_mse: 5.1705 - val_mae: 1.8179\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3455 - mse: 6.3455 - mae: 1.8239 - val_loss: 4.9620 - val_mse: 4.9620 - val_mae: 1.7836\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2662 - mse: 6.2662 - mae: 1.8263 - val_loss: 6.9531 - val_mse: 6.9531 - val_mae: 2.0664\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5806 - mse: 6.5806 - mae: 1.9173 - val_loss: 4.6059 - val_mse: 4.6059 - val_mae: 1.7240\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4977 - mse: 6.4977 - mae: 1.8416 - val_loss: 5.6506 - val_mse: 5.6506 - val_mae: 1.9026\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4458 - mse: 6.4458 - mae: 1.8714 - val_loss: 4.6821 - val_mse: 4.6821 - val_mae: 1.7258\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3228 - mse: 6.3228 - mae: 1.8248 - val_loss: 4.5789 - val_mse: 4.5789 - val_mae: 1.7151\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7253 - mse: 6.7253 - mae: 1.8679 - val_loss: 4.6283 - val_mse: 4.6283 - val_mae: 1.7168\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4147 - mse: 6.4147 - mae: 1.8416 - val_loss: 5.2893 - val_mse: 5.2893 - val_mae: 1.8311\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.5684 - mse: 6.5684 - mae: 1.8771 - val_loss: 4.6319 - val_mse: 4.6319 - val_mae: 1.7162\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5433 - mse: 6.5433 - mae: 1.8532 - val_loss: 5.8984 - val_mse: 5.8984 - val_mae: 1.9321\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4528 - mse: 6.4528 - mae: 1.8515 - val_loss: 4.7014 - val_mse: 4.7014 - val_mae: 1.7402\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5921 - mse: 6.5921 - mae: 1.9006 - val_loss: 4.6631 - val_mse: 4.6631 - val_mae: 1.7251\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.4026 - mse: 6.4026 - mae: 1.8517 - val_loss: 4.8551 - val_mse: 4.8551 - val_mae: 1.7608\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2979 - mse: 6.2979 - mae: 1.8189 - val_loss: 5.2025 - val_mse: 5.2025 - val_mae: 1.8197\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4457 - mse: 6.4457 - mae: 1.8520 - val_loss: 5.0820 - val_mse: 5.0820 - val_mae: 1.8175\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5364 - mse: 6.5364 - mae: 1.9081 - val_loss: 4.6187 - val_mse: 4.6187 - val_mae: 1.7252\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7918 - mse: 6.7918 - mae: 1.9132 - val_loss: 4.6219 - val_mse: 4.6219 - val_mae: 1.7232\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3217 - mse: 6.3217 - mae: 1.8224 - val_loss: 4.6449 - val_mse: 4.6449 - val_mae: 1.7218\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2283 - mse: 6.2283 - mae: 1.8127 - val_loss: 5.0485 - val_mse: 5.0485 - val_mae: 1.7994\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5707 - mse: 6.5707 - mae: 1.8415 - val_loss: 4.6590 - val_mse: 4.6590 - val_mae: 1.7374\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4514 - mse: 6.4514 - mae: 1.8545 - val_loss: 5.3153 - val_mse: 5.3153 - val_mae: 1.8375\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3658 - mse: 6.3658 - mae: 1.8256 - val_loss: 5.0286 - val_mse: 5.0286 - val_mae: 1.7972\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3033 - mse: 6.3033 - mae: 1.8319 - val_loss: 4.8866 - val_mse: 4.8866 - val_mae: 1.7714\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4206 - mse: 6.4206 - mae: 1.8332 - val_loss: 5.0915 - val_mse: 5.0915 - val_mae: 1.8072\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2541 - mse: 6.2541 - mae: 1.8192 - val_loss: 4.5630 - val_mse: 4.5630 - val_mae: 1.7056\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.2370 - mse: 6.2370 - mae: 1.8123 - val_loss: 5.4979 - val_mse: 5.4979 - val_mae: 1.8579\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2314 - mse: 6.2314 - mae: 1.8209 - val_loss: 4.6628 - val_mse: 4.6628 - val_mae: 1.7297\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3588 - mse: 6.3588 - mae: 1.8153 - val_loss: 5.6124 - val_mse: 5.6124 - val_mae: 1.8817\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3221 - mse: 6.3221 - mae: 1.8283 - val_loss: 4.7976 - val_mse: 4.7976 - val_mae: 1.7667\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.3446 - mse: 6.3446 - mae: 1.8517 - val_loss: 4.6916 - val_mse: 4.6916 - val_mae: 1.7347\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4286 - mse: 6.4286 - mae: 1.8551 - val_loss: 5.5610 - val_mse: 5.5610 - val_mae: 1.8780\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3185 - mse: 6.3185 - mae: 1.8256 - val_loss: 4.6483 - val_mse: 4.6483 - val_mae: 1.7343\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1249 - mse: 6.1249 - mae: 1.8181 - val_loss: 5.0275 - val_mse: 5.0275 - val_mae: 1.7814\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4719 - mse: 6.4719 - mae: 1.8354 - val_loss: 4.7068 - val_mse: 4.7068 - val_mae: 1.7565\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2521 - mse: 6.2521 - mae: 1.8211 - val_loss: 5.6370 - val_mse: 5.6370 - val_mae: 1.8817\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3696 - mse: 6.3696 - mae: 1.8480 - val_loss: 4.7783 - val_mse: 4.7783 - val_mae: 1.7561\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3967 - mse: 6.3967 - mae: 1.8338 - val_loss: 4.6079 - val_mse: 4.6079 - val_mae: 1.7189\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3138 - mse: 6.3138 - mae: 1.8230 - val_loss: 4.7921 - val_mse: 4.7921 - val_mae: 1.7523\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3139 - mse: 6.3139 - mae: 1.8462 - val_loss: 4.7081 - val_mse: 4.7081 - val_mae: 1.7761\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5035 - mse: 6.5035 - mae: 1.8504 - val_loss: 4.5780 - val_mse: 4.5780 - val_mae: 1.7215\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2115 - mse: 6.2115 - mae: 1.8161 - val_loss: 4.8432 - val_mse: 4.8432 - val_mae: 1.7621\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3583 - mse: 6.3583 - mae: 1.8523 - val_loss: 4.9776 - val_mse: 4.9776 - val_mae: 1.7926\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3386 - mse: 6.3386 - mae: 1.8270 - val_loss: 5.3743 - val_mse: 5.3743 - val_mae: 1.8507\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3638 - mse: 6.3638 - mae: 1.8368 - val_loss: 5.0272 - val_mse: 5.0272 - val_mae: 1.7988\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2145 - mse: 6.2145 - mae: 1.8219 - val_loss: 4.7742 - val_mse: 4.7742 - val_mae: 1.7560\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1506 - mse: 6.1506 - mae: 1.7876 - val_loss: 5.3725 - val_mse: 5.3725 - val_mae: 1.8517\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.1706 - mse: 6.1706 - mae: 1.7992 - val_loss: 4.7725 - val_mse: 4.7725 - val_mae: 1.7492\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2116 - mse: 6.2116 - mae: 1.8456 - val_loss: 4.9114 - val_mse: 4.9114 - val_mae: 1.7753\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3703 - mse: 6.3703 - mae: 1.7967 - val_loss: 4.7651 - val_mse: 4.7651 - val_mae: 1.7468\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3450 - mse: 6.3450 - mae: 1.8243 - val_loss: 4.7758 - val_mse: 4.7758 - val_mae: 1.7722\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4509 - mse: 6.4509 - mae: 1.8557 - val_loss: 5.4521 - val_mse: 5.4521 - val_mae: 1.8555\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2299 - mse: 6.2299 - mae: 1.8023 - val_loss: 4.7534 - val_mse: 4.7534 - val_mae: 1.7529\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2736 - mse: 6.2736 - mae: 1.8263 - val_loss: 4.6930 - val_mse: 4.6930 - val_mae: 1.7763\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6043 - mse: 6.6043 - mae: 1.8629 - val_loss: 4.9512 - val_mse: 4.9512 - val_mae: 1.7842\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3368 - mse: 6.3368 - mae: 1.8493 - val_loss: 5.2319 - val_mse: 5.2319 - val_mae: 1.8335\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3131 - mse: 6.3131 - mae: 1.8354 - val_loss: 4.7829 - val_mse: 4.7829 - val_mae: 1.7572\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2284 - mse: 6.2284 - mae: 1.8309 - val_loss: 4.5561 - val_mse: 4.5561 - val_mae: 1.7102\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2992 - mse: 6.2992 - mae: 1.8260 - val_loss: 4.7122 - val_mse: 4.7122 - val_mae: 1.7430\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1220 - mse: 6.1220 - mae: 1.7860 - val_loss: 4.7619 - val_mse: 4.7619 - val_mae: 1.7462\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2870 - mse: 6.2870 - mae: 1.8294 - val_loss: 4.6229 - val_mse: 4.6229 - val_mae: 1.7498\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3067 - mse: 6.3067 - mae: 1.8494 - val_loss: 4.8145 - val_mse: 4.8145 - val_mae: 1.7672\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3283 - mse: 6.3283 - mae: 1.8166 - val_loss: 4.4914 - val_mse: 4.4914 - val_mae: 1.6977\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2452 - mse: 6.2452 - mae: 1.8234 - val_loss: 4.5662 - val_mse: 4.5662 - val_mae: 1.7284\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.1846 - mse: 6.1846 - mae: 1.8084 - val_loss: 4.5263 - val_mse: 4.5263 - val_mae: 1.7107\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1806 - mse: 6.1806 - mae: 1.7929 - val_loss: 5.7047 - val_mse: 5.7047 - val_mae: 1.9003\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.1796 - mse: 6.1796 - mae: 1.8132 - val_loss: 5.0251 - val_mse: 5.0251 - val_mae: 1.7963\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1628 - mse: 6.1628 - mae: 1.7815 - val_loss: 4.9271 - val_mse: 4.9271 - val_mae: 1.7860\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0968 - mse: 6.0968 - mae: 1.7910 - val_loss: 6.7143 - val_mse: 6.7143 - val_mae: 2.0210\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6304 - mse: 6.6304 - mae: 1.8756 - val_loss: 4.6349 - val_mse: 4.6349 - val_mae: 1.7577\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0540 - mse: 6.0540 - mae: 1.7851 - val_loss: 4.8026 - val_mse: 4.8026 - val_mae: 1.7704\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3453 - mse: 6.3453 - mae: 1.8507 - val_loss: 4.7162 - val_mse: 4.7162 - val_mae: 1.7508\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0844 - mse: 6.0844 - mae: 1.8106 - val_loss: 5.0921 - val_mse: 5.0921 - val_mae: 1.8068\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1993 - mse: 6.1993 - mae: 1.8448 - val_loss: 4.4964 - val_mse: 4.4964 - val_mae: 1.6953\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0925 - mse: 6.0925 - mae: 1.7797 - val_loss: 6.1578 - val_mse: 6.1578 - val_mae: 1.9524\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3693 - mse: 6.3693 - mae: 1.8589 - val_loss: 5.1491 - val_mse: 5.1491 - val_mae: 1.8169\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2951 - mse: 6.2951 - mae: 1.8370 - val_loss: 4.4874 - val_mse: 4.4874 - val_mae: 1.7033\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9693 - mse: 5.9693 - mae: 1.8025 - val_loss: 4.7753 - val_mse: 4.7753 - val_mae: 1.7785\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9601 - mse: 5.9601 - mae: 1.7786 - val_loss: 6.5054 - val_mse: 6.5054 - val_mae: 2.0069\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2497 - mse: 6.2497 - mae: 1.8209 - val_loss: 4.9874 - val_mse: 4.9874 - val_mae: 1.8075\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2031 - mse: 6.2031 - mae: 1.8325 - val_loss: 4.6481 - val_mse: 4.6481 - val_mae: 1.7377\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.2720 - mse: 6.2720 - mae: 1.7905 - val_loss: 4.5906 - val_mse: 4.5906 - val_mae: 1.7475\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2834 - mse: 6.2834 - mae: 1.8302 - val_loss: 4.8040 - val_mse: 4.8040 - val_mae: 1.7704\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0973 - mse: 6.0973 - mae: 1.7982 - val_loss: 5.3435 - val_mse: 5.3435 - val_mae: 1.8481\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.2024 - mse: 6.2024 - mae: 1.8376 - val_loss: 4.7118 - val_mse: 4.7118 - val_mae: 1.7481\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2098 - mse: 6.2098 - mae: 1.8666 - val_loss: 4.5078 - val_mse: 4.5078 - val_mae: 1.7205\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2149 - mse: 6.2149 - mae: 1.7969 - val_loss: 5.3349 - val_mse: 5.3349 - val_mae: 1.8421\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1823 - mse: 6.1823 - mae: 1.7964 - val_loss: 5.1036 - val_mse: 5.1036 - val_mae: 1.8098\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1937 - mse: 6.1937 - mae: 1.8449 - val_loss: 4.6305 - val_mse: 4.6305 - val_mae: 1.7267\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0647 - mse: 6.0647 - mae: 1.7528 - val_loss: 4.5359 - val_mse: 4.5359 - val_mae: 1.7126\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1628 - mse: 6.1628 - mae: 1.8226 - val_loss: 4.8935 - val_mse: 4.8935 - val_mae: 1.7779\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9672 - mse: 5.9672 - mae: 1.7874 - val_loss: 4.4897 - val_mse: 4.4897 - val_mae: 1.7135\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4234 - mse: 6.4234 - mae: 1.8338 - val_loss: 4.9544 - val_mse: 4.9544 - val_mae: 1.7842\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2540 - mse: 6.2540 - mae: 1.8075 - val_loss: 4.5247 - val_mse: 4.5247 - val_mae: 1.7292\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.1156 - mse: 6.1156 - mae: 1.8209 - val_loss: 4.8472 - val_mse: 4.8472 - val_mae: 1.7735\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1618 - mse: 6.1618 - mae: 1.7860 - val_loss: 4.5476 - val_mse: 4.5476 - val_mae: 1.7213\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0746 - mse: 6.0746 - mae: 1.7831 - val_loss: 5.6607 - val_mse: 5.6607 - val_mae: 1.9026\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 6.4574 - mse: 6.4574 - mae: 1.8408 - val_loss: 5.0681 - val_mse: 5.0681 - val_mae: 1.8126\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9768 - mse: 5.9768 - mae: 1.7885 - val_loss: 4.7506 - val_mse: 4.7506 - val_mae: 1.7528\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.2045 - mse: 6.2045 - mae: 1.8107 - val_loss: 4.5437 - val_mse: 4.5437 - val_mae: 1.7304\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0910 - mse: 6.0910 - mae: 1.8006 - val_loss: 5.0040 - val_mse: 5.0040 - val_mae: 1.7862\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2446 - mse: 6.2446 - mae: 1.8129 - val_loss: 4.5370 - val_mse: 4.5370 - val_mae: 1.7359\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.3758 - mse: 6.3758 - mae: 1.8515 - val_loss: 4.5017 - val_mse: 4.5017 - val_mae: 1.7132\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.8965 - mse: 5.8965 - mae: 1.7388 - val_loss: 4.8775 - val_mse: 4.8775 - val_mae: 1.7833\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1740 - mse: 6.1740 - mae: 1.8125 - val_loss: 4.7226 - val_mse: 4.7226 - val_mae: 1.7508\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.9195 - mse: 5.9195 - mae: 1.7823 - val_loss: 4.4387 - val_mse: 4.4387 - val_mae: 1.6977\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1454 - mse: 6.1454 - mae: 1.8187 - val_loss: 4.8918 - val_mse: 4.8918 - val_mae: 1.7863\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.9011 - mse: 5.9011 - mae: 1.7949 - val_loss: 4.4696 - val_mse: 4.4696 - val_mae: 1.7124\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1545 - mse: 6.1545 - mae: 1.8075 - val_loss: 4.8681 - val_mse: 4.8681 - val_mae: 1.7816\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2440 - mse: 6.2440 - mae: 1.8245 - val_loss: 4.5011 - val_mse: 4.5011 - val_mae: 1.7141\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1039 - mse: 6.1039 - mae: 1.7973 - val_loss: 4.5501 - val_mse: 4.5501 - val_mae: 1.7213\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0150 - mse: 6.0150 - mae: 1.7960 - val_loss: 4.5276 - val_mse: 4.5276 - val_mae: 1.7375\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.9480 - mse: 5.9480 - mae: 1.7688 - val_loss: 4.5662 - val_mse: 4.5662 - val_mae: 1.7192\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1417 - mse: 6.1417 - mae: 1.7950 - val_loss: 4.5174 - val_mse: 4.5174 - val_mae: 1.7100\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9650 - mse: 5.9650 - mae: 1.7655 - val_loss: 4.5951 - val_mse: 4.5951 - val_mae: 1.7404\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1654 - mse: 6.1654 - mae: 1.7753 - val_loss: 4.8842 - val_mse: 4.8842 - val_mae: 1.7838\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9306 - mse: 5.9306 - mae: 1.7801 - val_loss: 4.6958 - val_mse: 4.6958 - val_mae: 1.7467\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0936 - mse: 6.0936 - mae: 1.8209 - val_loss: 4.8236 - val_mse: 4.8236 - val_mae: 1.7858\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1142 - mse: 6.1142 - mae: 1.8268 - val_loss: 4.5997 - val_mse: 4.5997 - val_mae: 1.7630\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0849 - mse: 6.0849 - mae: 1.7944 - val_loss: 4.7321 - val_mse: 4.7321 - val_mae: 1.7889\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1034 - mse: 6.1034 - mae: 1.7935 - val_loss: 5.4252 - val_mse: 5.4252 - val_mae: 1.8614\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9725 - mse: 5.9725 - mae: 1.7845 - val_loss: 4.6754 - val_mse: 4.6754 - val_mae: 1.7228\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0711 - mse: 6.0711 - mae: 1.7509 - val_loss: 4.9122 - val_mse: 4.9122 - val_mae: 1.7749\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0994 - mse: 6.0994 - mae: 1.7885 - val_loss: 4.6374 - val_mse: 4.6374 - val_mae: 1.7486\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9464 - mse: 5.9464 - mae: 1.7844 - val_loss: 4.7641 - val_mse: 4.7641 - val_mae: 1.8090\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2447 - mse: 6.2447 - mae: 1.8257 - val_loss: 5.1597 - val_mse: 5.1597 - val_mae: 1.8190\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8648 - mse: 5.8648 - mae: 1.7652 - val_loss: 4.5777 - val_mse: 4.5777 - val_mae: 1.7399\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1362 - mse: 6.1362 - mae: 1.8132 - val_loss: 5.0654 - val_mse: 5.0654 - val_mae: 1.8079\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9368 - mse: 5.9368 - mae: 1.7813 - val_loss: 5.3333 - val_mse: 5.3333 - val_mae: 1.8412\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9319 - mse: 5.9319 - mae: 1.8063 - val_loss: 4.5195 - val_mse: 4.5195 - val_mae: 1.7094\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8390 - mse: 5.8390 - mae: 1.7694 - val_loss: 4.6843 - val_mse: 4.6843 - val_mae: 1.7939\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1888 - mse: 6.1888 - mae: 1.8119 - val_loss: 4.9135 - val_mse: 4.9135 - val_mae: 1.7826\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9790 - mse: 5.9790 - mae: 1.7886 - val_loss: 4.9198 - val_mse: 4.9198 - val_mae: 1.7922\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9507 - mse: 5.9507 - mae: 1.7686 - val_loss: 4.5061 - val_mse: 4.5061 - val_mae: 1.7329\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1100 - mse: 6.1100 - mae: 1.8204 - val_loss: 4.5057 - val_mse: 4.5057 - val_mae: 1.7339\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9461 - mse: 5.9461 - mae: 1.7727 - val_loss: 4.6625 - val_mse: 4.6625 - val_mae: 1.7481\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8640 - mse: 5.8640 - mae: 1.7648 - val_loss: 4.5006 - val_mse: 4.5006 - val_mae: 1.7057\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8585 - mse: 5.8585 - mae: 1.7645 - val_loss: 4.4387 - val_mse: 4.4387 - val_mae: 1.7237\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1878 - mse: 6.1878 - mae: 1.8134 - val_loss: 5.4787 - val_mse: 5.4787 - val_mae: 1.8689\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2643 - mse: 6.2643 - mae: 1.8159 - val_loss: 4.4861 - val_mse: 4.4861 - val_mae: 1.7140\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8373 - mse: 5.8373 - mae: 1.7479 - val_loss: 4.5741 - val_mse: 4.5741 - val_mae: 1.7331\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9146 - mse: 5.9146 - mae: 1.7531 - val_loss: 4.8534 - val_mse: 4.8534 - val_mae: 1.7696\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9484 - mse: 5.9484 - mae: 1.7718 - val_loss: 5.1017 - val_mse: 5.1017 - val_mae: 1.8117\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2320 - mse: 6.2320 - mae: 1.8184 - val_loss: 4.5203 - val_mse: 4.5203 - val_mae: 1.7383\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9562 - mse: 5.9562 - mae: 1.7935 - val_loss: 4.4211 - val_mse: 4.4211 - val_mae: 1.6972\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7725 - mse: 5.7725 - mae: 1.7471 - val_loss: 5.6324 - val_mse: 5.6324 - val_mae: 1.9227\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9811 - mse: 5.9811 - mae: 1.7796 - val_loss: 5.5764 - val_mse: 5.5764 - val_mae: 1.8970\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9828 - mse: 5.9828 - mae: 1.7621 - val_loss: 4.6437 - val_mse: 4.6437 - val_mae: 1.7342\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8467 - mse: 5.8467 - mae: 1.7693 - val_loss: 5.0161 - val_mse: 5.0161 - val_mae: 1.8033\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0943 - mse: 6.0943 - mae: 1.7939 - val_loss: 5.0347 - val_mse: 5.0347 - val_mae: 1.8008\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9347 - mse: 5.9347 - mae: 1.8105 - val_loss: 4.5257 - val_mse: 4.5257 - val_mae: 1.7143\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0738 - mse: 6.0738 - mae: 1.7784 - val_loss: 4.4191 - val_mse: 4.4191 - val_mae: 1.7135\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9453 - mse: 5.9453 - mae: 1.7745 - val_loss: 4.3850 - val_mse: 4.3850 - val_mae: 1.7036\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9209 - mse: 5.9209 - mae: 1.7500 - val_loss: 4.9074 - val_mse: 4.9074 - val_mae: 1.7790\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0010 - mse: 6.0010 - mae: 1.8044 - val_loss: 4.7286 - val_mse: 4.7286 - val_mae: 1.7627\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8894 - mse: 5.8894 - mae: 1.7525 - val_loss: 4.3906 - val_mse: 4.3906 - val_mae: 1.6913\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9527 - mse: 5.9527 - mae: 1.7381 - val_loss: 4.4504 - val_mse: 4.4504 - val_mae: 1.7343\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7610 - mse: 5.7610 - mae: 1.7286 - val_loss: 4.4851 - val_mse: 4.4851 - val_mae: 1.7348\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8720 - mse: 5.8720 - mae: 1.7597 - val_loss: 4.4077 - val_mse: 4.4077 - val_mae: 1.6835\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1734 - mse: 6.1734 - mae: 1.8207 - val_loss: 4.4660 - val_mse: 4.4660 - val_mae: 1.6985\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8570 - mse: 5.8570 - mae: 1.7643 - val_loss: 4.6377 - val_mse: 4.6377 - val_mae: 1.7299\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7811 - mse: 5.7811 - mae: 1.7453 - val_loss: 4.4161 - val_mse: 4.4161 - val_mae: 1.7205\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.8154 - mse: 5.8154 - mae: 1.7436 - val_loss: 6.0867 - val_mse: 6.0867 - val_mae: 1.9784\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2096 - mse: 6.2096 - mae: 1.8058 - val_loss: 4.8081 - val_mse: 4.8081 - val_mae: 1.7747\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7966 - mse: 5.7966 - mae: 1.7468 - val_loss: 4.5796 - val_mse: 4.5796 - val_mae: 1.7402\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.8673 - mse: 5.8673 - mae: 1.7535 - val_loss: 5.0791 - val_mse: 5.0791 - val_mae: 1.8107\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8063 - mse: 5.8063 - mae: 1.7620 - val_loss: 4.4399 - val_mse: 4.4399 - val_mae: 1.6927\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8580 - mse: 5.8580 - mae: 1.7656 - val_loss: 4.8282 - val_mse: 4.8282 - val_mae: 1.7606\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8559 - mse: 5.8559 - mae: 1.7574 - val_loss: 4.6051 - val_mse: 4.6051 - val_mae: 1.7221\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7223 - mse: 5.7223 - mae: 1.7302 - val_loss: 5.2652 - val_mse: 5.2652 - val_mae: 1.8398\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0782 - mse: 6.0782 - mae: 1.7985 - val_loss: 4.7748 - val_mse: 4.7748 - val_mae: 1.7584\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9981 - mse: 5.9981 - mae: 1.7650 - val_loss: 4.3987 - val_mse: 4.3987 - val_mae: 1.7086\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8169 - mse: 5.8169 - mae: 1.7421 - val_loss: 4.5595 - val_mse: 4.5595 - val_mae: 1.7172\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8012 - mse: 5.8012 - mae: 1.7368 - val_loss: 4.5440 - val_mse: 4.5440 - val_mae: 1.7175\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9175 - mse: 5.9175 - mae: 1.7345 - val_loss: 4.8640 - val_mse: 4.8640 - val_mae: 1.7805\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9194 - mse: 5.9194 - mae: 1.7532 - val_loss: 4.7839 - val_mse: 4.7839 - val_mae: 1.7693\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9008 - mse: 5.9008 - mae: 1.7745 - val_loss: 4.3459 - val_mse: 4.3459 - val_mae: 1.6981\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8523 - mse: 5.8523 - mae: 1.7515 - val_loss: 4.6293 - val_mse: 4.6293 - val_mae: 1.7398\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7878 - mse: 5.7878 - mae: 1.7369 - val_loss: 4.6239 - val_mse: 4.6239 - val_mae: 1.7585\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7943 - mse: 5.7943 - mae: 1.7541 - val_loss: 5.3172 - val_mse: 5.3172 - val_mae: 1.8525\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9069 - mse: 5.9069 - mae: 1.7627 - val_loss: 4.3973 - val_mse: 4.3973 - val_mae: 1.7038\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8243 - mse: 5.8243 - mae: 1.7458 - val_loss: 4.4744 - val_mse: 4.4744 - val_mae: 1.7255\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9659 - mse: 5.9659 - mae: 1.7561 - val_loss: 4.4701 - val_mse: 4.4701 - val_mae: 1.7317\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8988 - mse: 5.8988 - mae: 1.7702 - val_loss: 4.5717 - val_mse: 4.5717 - val_mae: 1.7141\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9487 - mse: 5.9487 - mae: 1.7513 - val_loss: 4.8208 - val_mse: 4.8208 - val_mae: 1.7724\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5784 - mse: 5.5784 - mae: 1.7251 - val_loss: 4.5800 - val_mse: 4.5800 - val_mae: 1.7317\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0491 - mse: 6.0491 - mae: 1.7942 - val_loss: 4.2940 - val_mse: 4.2940 - val_mae: 1.6735\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6637 - mse: 5.6637 - mae: 1.7016 - val_loss: 4.4368 - val_mse: 4.4368 - val_mae: 1.6944\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8181 - mse: 5.8181 - mae: 1.7520 - val_loss: 4.6812 - val_mse: 4.6812 - val_mae: 1.7402\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7882 - mse: 5.7882 - mae: 1.7454 - val_loss: 4.2924 - val_mse: 4.2924 - val_mae: 1.6670\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7629 - mse: 5.7629 - mae: 1.7453 - val_loss: 4.3365 - val_mse: 4.3365 - val_mae: 1.6942\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6586 - mse: 5.6586 - mae: 1.7222 - val_loss: 5.4006 - val_mse: 5.4006 - val_mae: 1.8707\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.8453 - mse: 5.8453 - mae: 1.7390 - val_loss: 4.4001 - val_mse: 4.4001 - val_mae: 1.7347\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6921 - mse: 5.6921 - mae: 1.7188 - val_loss: 4.4089 - val_mse: 4.4089 - val_mae: 1.7262\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9223 - mse: 5.9223 - mae: 1.7491 - val_loss: 4.5735 - val_mse: 4.5735 - val_mae: 1.7403\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8655 - mse: 5.8655 - mae: 1.7627 - val_loss: 4.4572 - val_mse: 4.4572 - val_mae: 1.7284\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7952 - mse: 5.7952 - mae: 1.7444 - val_loss: 5.2922 - val_mse: 5.2922 - val_mae: 1.8525\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7842 - mse: 5.7842 - mae: 1.7563 - val_loss: 4.6635 - val_mse: 4.6635 - val_mae: 1.7390\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7298 - mse: 5.7298 - mae: 1.7261 - val_loss: 4.4003 - val_mse: 4.4003 - val_mae: 1.7215\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0798 - mse: 6.0798 - mae: 1.7990 - val_loss: 5.0833 - val_mse: 5.0833 - val_mae: 1.8231\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6040 - mse: 5.6040 - mae: 1.7253 - val_loss: 4.4013 - val_mse: 4.4013 - val_mae: 1.7219\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9647 - mse: 5.9647 - mae: 1.7993 - val_loss: 4.3645 - val_mse: 4.3645 - val_mae: 1.6838\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7487 - mse: 5.7487 - mae: 1.7215 - val_loss: 4.4283 - val_mse: 4.4283 - val_mae: 1.7139\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7239 - mse: 5.7239 - mae: 1.7343 - val_loss: 4.8114 - val_mse: 4.8114 - val_mae: 1.7665\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6775 - mse: 5.6775 - mae: 1.7393 - val_loss: 4.9953 - val_mse: 4.9953 - val_mae: 1.7972\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9439 - mse: 5.9439 - mae: 1.7745 - val_loss: 5.7647 - val_mse: 5.7647 - val_mae: 1.9312\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.6609 - mse: 5.6609 - mae: 1.7595 - val_loss: 4.5823 - val_mse: 4.5823 - val_mae: 1.7587\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7913 - mse: 5.7913 - mae: 1.7540 - val_loss: 4.3192 - val_mse: 4.3192 - val_mae: 1.6974\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8109 - mse: 5.8109 - mae: 1.7255 - val_loss: 4.6727 - val_mse: 4.6727 - val_mae: 1.7374\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6044 - mse: 5.6044 - mae: 1.7132 - val_loss: 5.3384 - val_mse: 5.3384 - val_mae: 1.8414\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8411 - mse: 5.8411 - mae: 1.7720 - val_loss: 4.6079 - val_mse: 4.6079 - val_mae: 1.7222\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.6133 - mse: 5.6133 - mae: 1.7068 - val_loss: 4.3859 - val_mse: 4.3859 - val_mae: 1.7005\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6445 - mse: 5.6445 - mae: 1.7303 - val_loss: 4.5020 - val_mse: 4.5020 - val_mae: 1.7224\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.8973 - mse: 5.8973 - mae: 1.7666 - val_loss: 4.4935 - val_mse: 4.4935 - val_mae: 1.7278\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6203 - mse: 5.6203 - mae: 1.7187 - val_loss: 5.3931 - val_mse: 5.3931 - val_mae: 1.8622\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7065 - mse: 5.7065 - mae: 1.7404 - val_loss: 4.3949 - val_mse: 4.3949 - val_mae: 1.7299\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5244 - mse: 5.5244 - mae: 1.7081 - val_loss: 4.4701 - val_mse: 4.4701 - val_mae: 1.7522\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5638 - mse: 5.5638 - mae: 1.7583 - val_loss: 4.2629 - val_mse: 4.2629 - val_mae: 1.6484\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1734 - mse: 6.1734 - mae: 1.8243 - val_loss: 4.2755 - val_mse: 4.2755 - val_mae: 1.6722\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6806 - mse: 5.6806 - mae: 1.7143 - val_loss: 4.2719 - val_mse: 4.2719 - val_mae: 1.6876\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5823 - mse: 5.5823 - mae: 1.6969 - val_loss: 4.4322 - val_mse: 4.4322 - val_mae: 1.6927\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.8856 - mse: 5.8856 - mae: 1.7731 - val_loss: 4.2491 - val_mse: 4.2491 - val_mae: 1.6682\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9773 - mse: 5.9773 - mae: 1.7450 - val_loss: 4.3736 - val_mse: 4.3736 - val_mae: 1.7069\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6379 - mse: 5.6379 - mae: 1.7334 - val_loss: 4.4922 - val_mse: 4.4922 - val_mae: 1.7187\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6396 - mse: 5.6396 - mae: 1.7082 - val_loss: 4.4279 - val_mse: 4.4279 - val_mae: 1.7098\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8975 - mse: 5.8975 - mae: 1.7577 - val_loss: 4.3816 - val_mse: 4.3816 - val_mae: 1.6869\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.8050 - mse: 5.8050 - mae: 1.7585 - val_loss: 4.3939 - val_mse: 4.3939 - val_mae: 1.7313\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8571 - mse: 5.8571 - mae: 1.7662 - val_loss: 4.2961 - val_mse: 4.2961 - val_mae: 1.6795\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5772 - mse: 5.5772 - mae: 1.7126 - val_loss: 4.3823 - val_mse: 4.3823 - val_mae: 1.7257\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5417 - mse: 5.5417 - mae: 1.6922 - val_loss: 4.4555 - val_mse: 4.4555 - val_mae: 1.7265\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9932 - mse: 5.9932 - mae: 1.7884 - val_loss: 4.2355 - val_mse: 4.2355 - val_mae: 1.6594\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6028 - mse: 5.6028 - mae: 1.6993 - val_loss: 5.6664 - val_mse: 5.6664 - val_mae: 1.9336\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6107 - mse: 5.6107 - mae: 1.6831 - val_loss: 4.3362 - val_mse: 4.3362 - val_mae: 1.7036\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5916 - mse: 5.5916 - mae: 1.6929 - val_loss: 4.2344 - val_mse: 4.2344 - val_mae: 1.6568\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6632 - mse: 5.6632 - mae: 1.7429 - val_loss: 4.2726 - val_mse: 4.2726 - val_mae: 1.6592\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9317 - mse: 5.9317 - mae: 1.7875 - val_loss: 4.5606 - val_mse: 4.5606 - val_mae: 1.7159\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6512 - mse: 5.6512 - mae: 1.7334 - val_loss: 5.9343 - val_mse: 5.9343 - val_mae: 1.9547\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7576 - mse: 5.7576 - mae: 1.7506 - val_loss: 4.9360 - val_mse: 4.9360 - val_mae: 1.7817\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5266 - mse: 5.5266 - mae: 1.7035 - val_loss: 4.9815 - val_mse: 4.9815 - val_mae: 1.7902\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5280 - mse: 5.5280 - mae: 1.6764 - val_loss: 4.9868 - val_mse: 4.9868 - val_mae: 1.7956\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5541 - mse: 5.5541 - mae: 1.7122 - val_loss: 4.2974 - val_mse: 4.2974 - val_mae: 1.6850\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.6778 - mse: 5.6778 - mae: 1.7317 - val_loss: 4.9650 - val_mse: 4.9650 - val_mae: 1.7977\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.7184 - mse: 5.7184 - mae: 1.7292 - val_loss: 5.4555 - val_mse: 5.4555 - val_mae: 1.8642\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.7567 - mse: 5.7567 - mae: 1.7178 - val_loss: 4.6535 - val_mse: 4.6535 - val_mae: 1.7391\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.4327 - mse: 5.4327 - mae: 1.6856 - val_loss: 4.6871 - val_mse: 4.6871 - val_mae: 1.7502\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.4643 - mse: 5.4643 - mae: 1.6981 - val_loss: 4.3922 - val_mse: 4.3922 - val_mae: 1.7079\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0240 - mse: 6.0240 - mae: 1.7914 - val_loss: 4.2671 - val_mse: 4.2671 - val_mae: 1.6821\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7703 - mse: 5.7703 - mae: 1.7305 - val_loss: 4.9278 - val_mse: 4.9278 - val_mae: 1.7864\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7414 - mse: 5.7414 - mae: 1.7297 - val_loss: 4.2674 - val_mse: 4.2674 - val_mae: 1.6878\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5594 - mse: 5.5594 - mae: 1.7192 - val_loss: 4.5235 - val_mse: 4.5235 - val_mae: 1.7154\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5787 - mse: 5.5787 - mae: 1.6992 - val_loss: 4.5837 - val_mse: 4.5837 - val_mae: 1.7192\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6703 - mse: 5.6703 - mae: 1.7360 - val_loss: 4.4317 - val_mse: 4.4317 - val_mae: 1.6924\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4581 - mse: 5.4581 - mae: 1.7401 - val_loss: 4.4672 - val_mse: 4.4672 - val_mae: 1.7057\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6434 - mse: 5.6434 - mae: 1.7073 - val_loss: 4.6739 - val_mse: 4.6739 - val_mae: 1.7510\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7201 - mse: 5.7201 - mae: 1.7341 - val_loss: 4.8371 - val_mse: 4.8371 - val_mae: 1.7671\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6330 - mse: 5.6330 - mae: 1.7141 - val_loss: 4.3973 - val_mse: 4.3973 - val_mae: 1.7135\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6084 - mse: 5.6084 - mae: 1.7228 - val_loss: 4.3426 - val_mse: 4.3426 - val_mae: 1.7099\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.5266 - mse: 5.5266 - mae: 1.7182 - val_loss: 4.2389 - val_mse: 4.2389 - val_mae: 1.6785\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.5183 - mse: 5.5183 - mae: 1.7086 - val_loss: 5.2392 - val_mse: 5.2392 - val_mae: 1.8383\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.0768 - mse: 6.0768 - mae: 1.7858 - val_loss: 4.3653 - val_mse: 4.3653 - val_mae: 1.6962\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4930 - mse: 5.4930 - mae: 1.6963 - val_loss: 4.3255 - val_mse: 4.3255 - val_mae: 1.7069\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4953 - mse: 5.4953 - mae: 1.6905 - val_loss: 4.3355 - val_mse: 4.3355 - val_mae: 1.7004\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5739 - mse: 5.5739 - mae: 1.7188 - val_loss: 4.1904 - val_mse: 4.1904 - val_mae: 1.6568\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7675 - mse: 5.7675 - mae: 1.7519 - val_loss: 4.2487 - val_mse: 4.2487 - val_mae: 1.6737\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4994 - mse: 5.4994 - mae: 1.6993 - val_loss: 4.4102 - val_mse: 4.4102 - val_mae: 1.6885\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.6838 - mse: 5.6838 - mae: 1.7301 - val_loss: 4.4229 - val_mse: 4.4229 - val_mae: 1.6940\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5210 - mse: 5.5210 - mae: 1.6866 - val_loss: 4.4945 - val_mse: 4.4945 - val_mae: 1.7044\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6052 - mse: 5.6052 - mae: 1.6958 - val_loss: 4.4421 - val_mse: 4.4421 - val_mae: 1.7092\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6217 - mse: 5.6217 - mae: 1.7098 - val_loss: 4.3475 - val_mse: 4.3475 - val_mae: 1.7010\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6412 - mse: 5.6412 - mae: 1.7239 - val_loss: 4.3887 - val_mse: 4.3887 - val_mae: 1.7253\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.4201 - mse: 5.4201 - mae: 1.7180 - val_loss: 5.2956 - val_mse: 5.2956 - val_mae: 1.8401\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.4462 - mse: 5.4462 - mae: 1.6809 - val_loss: 4.3970 - val_mse: 4.3970 - val_mae: 1.7257\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.5536 - mse: 5.5536 - mae: 1.7187 - val_loss: 4.3909 - val_mse: 4.3909 - val_mae: 1.7282\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5496 - mse: 5.5496 - mae: 1.7342 - val_loss: 4.5258 - val_mse: 4.5258 - val_mae: 1.7439\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4821 - mse: 5.4821 - mae: 1.6999 - val_loss: 5.0082 - val_mse: 5.0082 - val_mae: 1.7988\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5708 - mse: 5.5708 - mae: 1.7264 - val_loss: 4.2585 - val_mse: 4.2585 - val_mae: 1.6737\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6272 - mse: 5.6272 - mae: 1.7285 - val_loss: 4.2435 - val_mse: 4.2435 - val_mae: 1.6702\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6408 - mse: 5.6408 - mae: 1.7108 - val_loss: 4.4013 - val_mse: 4.4013 - val_mae: 1.6995\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5022 - mse: 5.5022 - mae: 1.6995 - val_loss: 4.9497 - val_mse: 4.9497 - val_mae: 1.8061\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4617 - mse: 5.4617 - mae: 1.6729 - val_loss: 4.2531 - val_mse: 4.2531 - val_mae: 1.6544\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5529 - mse: 5.5529 - mae: 1.6914 - val_loss: 4.5016 - val_mse: 4.5016 - val_mae: 1.7197\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5387 - mse: 5.5387 - mae: 1.7253 - val_loss: 4.4830 - val_mse: 4.4830 - val_mae: 1.7535\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5325 - mse: 5.5325 - mae: 1.7208 - val_loss: 4.5079 - val_mse: 4.5079 - val_mae: 1.7618\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5384 - mse: 5.5384 - mae: 1.7446 - val_loss: 4.5405 - val_mse: 4.5405 - val_mae: 1.7201\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.4188 - mse: 5.4188 - mae: 1.7037 - val_loss: 4.4004 - val_mse: 4.4004 - val_mae: 1.6926\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5260 - mse: 5.5260 - mae: 1.6782 - val_loss: 4.2711 - val_mse: 4.2711 - val_mae: 1.6772\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5181 - mse: 5.5181 - mae: 1.7083 - val_loss: 4.2269 - val_mse: 4.2269 - val_mae: 1.6855\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7450 - mse: 5.7450 - mae: 1.7516 - val_loss: 4.2017 - val_mse: 4.2017 - val_mae: 1.6636\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.5760 - mse: 5.5760 - mae: 1.7011 - val_loss: 4.3617 - val_mse: 4.3617 - val_mae: 1.6949\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6254 - mse: 5.6254 - mae: 1.7198 - val_loss: 4.4830 - val_mse: 4.4830 - val_mae: 1.7360\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6357 - mse: 5.6357 - mae: 1.7208 - val_loss: 4.5401 - val_mse: 4.5401 - val_mae: 1.7148\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6485 - mse: 5.6485 - mae: 1.7075 - val_loss: 4.2818 - val_mse: 4.2818 - val_mae: 1.6894\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3925 - mse: 5.3925 - mae: 1.6878 - val_loss: 4.6905 - val_mse: 4.6905 - val_mae: 1.7455\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3415 - mse: 5.3415 - mae: 1.6938 - val_loss: 4.9837 - val_mse: 4.9837 - val_mae: 1.8107\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4912 - mse: 5.4912 - mae: 1.7591 - val_loss: 4.3342 - val_mse: 4.3342 - val_mae: 1.6714\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6010 - mse: 5.6010 - mae: 1.6968 - val_loss: 4.3051 - val_mse: 4.3051 - val_mae: 1.7010\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7009 - mse: 5.7009 - mae: 1.7659 - val_loss: 4.4441 - val_mse: 4.4441 - val_mae: 1.6978\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6310 - mse: 5.6310 - mae: 1.7199 - val_loss: 4.3005 - val_mse: 4.3005 - val_mae: 1.6891\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4385 - mse: 5.4385 - mae: 1.7021 - val_loss: 4.1622 - val_mse: 4.1622 - val_mae: 1.6291\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5448 - mse: 5.5448 - mae: 1.6821 - val_loss: 4.5556 - val_mse: 4.5556 - val_mae: 1.7211\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2941 - mse: 5.2941 - mae: 1.7025 - val_loss: 4.1688 - val_mse: 4.1688 - val_mae: 1.6302\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4582 - mse: 5.4582 - mae: 1.6733 - val_loss: 4.2737 - val_mse: 4.2737 - val_mae: 1.6706\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3082 - mse: 5.3082 - mae: 1.6660 - val_loss: 4.2450 - val_mse: 4.2450 - val_mae: 1.6724\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3249 - mse: 5.3249 - mae: 1.6421 - val_loss: 4.5615 - val_mse: 4.5615 - val_mae: 1.7241\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.3129 - mse: 5.3129 - mae: 1.7038 - val_loss: 4.2321 - val_mse: 4.2321 - val_mae: 1.6738\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3117 - mse: 5.3117 - mae: 1.6682 - val_loss: 4.2929 - val_mse: 4.2929 - val_mae: 1.6639\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3372 - mse: 5.3372 - mae: 1.6925 - val_loss: 4.1058 - val_mse: 4.1058 - val_mae: 1.6289\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3985 - mse: 5.3985 - mae: 1.6761 - val_loss: 4.9947 - val_mse: 4.9947 - val_mae: 1.8171\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5891 - mse: 5.5891 - mae: 1.7160 - val_loss: 4.2004 - val_mse: 4.2004 - val_mae: 1.6572\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5036 - mse: 5.5036 - mae: 1.7095 - val_loss: 4.3490 - val_mse: 4.3490 - val_mae: 1.7185\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3263 - mse: 5.3263 - mae: 1.6718 - val_loss: 4.2552 - val_mse: 4.2552 - val_mae: 1.6581\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3237 - mse: 5.3237 - mae: 1.6899 - val_loss: 5.3165 - val_mse: 5.3165 - val_mae: 1.8545\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.4104 - mse: 5.4104 - mae: 1.6927 - val_loss: 5.7301 - val_mse: 5.7301 - val_mae: 1.9214\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6706 - mse: 5.6706 - mae: 1.7319 - val_loss: 4.7442 - val_mse: 4.7442 - val_mae: 1.7586\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2756 - mse: 5.2756 - mae: 1.6654 - val_loss: 5.4449 - val_mse: 5.4449 - val_mae: 1.8814\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.6211 - mse: 5.6211 - mae: 1.7335 - val_loss: 4.2092 - val_mse: 4.2092 - val_mae: 1.6566\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.2483 - mse: 5.2483 - mae: 1.6261 - val_loss: 4.5288 - val_mse: 4.5288 - val_mae: 1.7237\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5781 - mse: 5.5781 - mae: 1.7276 - val_loss: 5.5495 - val_mse: 5.5495 - val_mae: 1.8955\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.3728 - mse: 5.3728 - mae: 1.6807 - val_loss: 4.5595 - val_mse: 4.5595 - val_mae: 1.7392\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.3148 - mse: 5.3148 - mae: 1.6708 - val_loss: 4.4251 - val_mse: 4.4251 - val_mae: 1.7085\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7989 - mse: 5.7989 - mae: 1.7556 - val_loss: 4.4536 - val_mse: 4.4536 - val_mae: 1.7174\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.4315 - mse: 5.4315 - mae: 1.6707 - val_loss: 5.0372 - val_mse: 5.0372 - val_mae: 1.8050\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.4879 - mse: 5.4879 - mae: 1.7039 - val_loss: 4.3687 - val_mse: 4.3687 - val_mae: 1.7209\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3789 - mse: 5.3789 - mae: 1.6769 - val_loss: 4.3905 - val_mse: 4.3905 - val_mae: 1.7004\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3344 - mse: 5.3344 - mae: 1.6469 - val_loss: 5.5411 - val_mse: 5.5411 - val_mae: 1.8934\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3313 - mse: 5.3313 - mae: 1.6670 - val_loss: 4.2677 - val_mse: 4.2677 - val_mae: 1.6828\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4652 - mse: 5.4652 - mae: 1.6983 - val_loss: 4.2864 - val_mse: 4.2864 - val_mae: 1.6875\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4454 - mse: 5.4454 - mae: 1.6973 - val_loss: 4.3026 - val_mse: 4.3026 - val_mae: 1.6824\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2188 - mse: 5.2188 - mae: 1.6657 - val_loss: 4.2051 - val_mse: 4.2051 - val_mae: 1.6685\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3674 - mse: 5.3674 - mae: 1.6844 - val_loss: 4.5791 - val_mse: 4.5791 - val_mae: 1.7296\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5514 - mse: 5.5514 - mae: 1.7024 - val_loss: 4.2337 - val_mse: 4.2337 - val_mae: 1.6750\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3068 - mse: 5.3068 - mae: 1.6508 - val_loss: 4.4537 - val_mse: 4.4537 - val_mae: 1.7293\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2650 - mse: 5.2650 - mae: 1.6678 - val_loss: 4.1615 - val_mse: 4.1615 - val_mae: 1.6454\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4368 - mse: 5.4368 - mae: 1.7016 - val_loss: 4.1805 - val_mse: 4.1805 - val_mae: 1.6596\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.4826 - mse: 5.4826 - mae: 1.6966 - val_loss: 4.2287 - val_mse: 4.2287 - val_mae: 1.6706\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5175 - mse: 5.5175 - mae: 1.7043 - val_loss: 4.4134 - val_mse: 4.4134 - val_mae: 1.6980\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2263 - mse: 5.2263 - mae: 1.6540 - val_loss: 4.7996 - val_mse: 4.7996 - val_mae: 1.7742\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3866 - mse: 5.3866 - mae: 1.6923 - val_loss: 4.1932 - val_mse: 4.1932 - val_mae: 1.6617\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3998 - mse: 5.3998 - mae: 1.7105 - val_loss: 4.2241 - val_mse: 4.2241 - val_mae: 1.6712\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2132 - mse: 5.2132 - mae: 1.6453 - val_loss: 4.5521 - val_mse: 4.5521 - val_mae: 1.7235\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2820 - mse: 5.2820 - mae: 1.6603 - val_loss: 4.2482 - val_mse: 4.2482 - val_mae: 1.6758\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3768 - mse: 5.3768 - mae: 1.6768 - val_loss: 4.1205 - val_mse: 4.1205 - val_mae: 1.6296\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2931 - mse: 5.2931 - mae: 1.6344 - val_loss: 4.3308 - val_mse: 4.3308 - val_mae: 1.6824\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3371 - mse: 5.3371 - mae: 1.6756 - val_loss: 4.7038 - val_mse: 4.7038 - val_mae: 1.7506\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2974 - mse: 5.2974 - mae: 1.6671 - val_loss: 4.3822 - val_mse: 4.3822 - val_mae: 1.7089\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2708 - mse: 5.2708 - mae: 1.6680 - val_loss: 4.1616 - val_mse: 4.1616 - val_mae: 1.6368\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3285 - mse: 5.3285 - mae: 1.6323 - val_loss: 4.7472 - val_mse: 4.7472 - val_mae: 1.7583\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1774 - mse: 5.1774 - mae: 1.6447 - val_loss: 4.9000 - val_mse: 4.9000 - val_mae: 1.7754\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3978 - mse: 5.3978 - mae: 1.6836 - val_loss: 4.1988 - val_mse: 4.1988 - val_mae: 1.6709\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4939 - mse: 5.4939 - mae: 1.6625 - val_loss: 4.2371 - val_mse: 4.2371 - val_mae: 1.6782\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.1993 - mse: 5.1993 - mae: 1.6497 - val_loss: 4.6318 - val_mse: 4.6318 - val_mae: 1.7409\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2537 - mse: 5.2537 - mae: 1.6791 - val_loss: 4.1723 - val_mse: 4.1723 - val_mae: 1.6487\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3549 - mse: 5.3549 - mae: 1.6617 - val_loss: 4.3535 - val_mse: 4.3535 - val_mae: 1.7105\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0525 - mse: 5.0525 - mae: 1.6230 - val_loss: 5.6090 - val_mse: 5.6090 - val_mae: 1.9239\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4563 - mse: 5.4563 - mae: 1.6849 - val_loss: 4.5429 - val_mse: 4.5429 - val_mae: 1.7296\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2438 - mse: 5.2438 - mae: 1.6771 - val_loss: 4.1231 - val_mse: 4.1231 - val_mae: 1.6366\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2291 - mse: 5.2291 - mae: 1.6313 - val_loss: 4.3381 - val_mse: 4.3381 - val_mae: 1.6949\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3051 - mse: 5.3051 - mae: 1.6649 - val_loss: 4.2648 - val_mse: 4.2648 - val_mae: 1.6844\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4465 - mse: 5.4465 - mae: 1.7264 - val_loss: 4.2579 - val_mse: 4.2579 - val_mae: 1.6656\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2311 - mse: 5.2311 - mae: 1.6591 - val_loss: 4.4227 - val_mse: 4.4227 - val_mae: 1.7281\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4068 - mse: 5.4068 - mae: 1.6528 - val_loss: 4.3733 - val_mse: 4.3733 - val_mae: 1.6990\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3215 - mse: 5.3215 - mae: 1.7019 - val_loss: 4.2546 - val_mse: 4.2546 - val_mae: 1.6772\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4552 - mse: 5.4552 - mae: 1.7175 - val_loss: 4.3122 - val_mse: 4.3122 - val_mae: 1.6713\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2515 - mse: 5.2515 - mae: 1.6588 - val_loss: 4.2539 - val_mse: 4.2539 - val_mae: 1.6693\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2111 - mse: 5.2111 - mae: 1.6417 - val_loss: 4.0585 - val_mse: 4.0585 - val_mae: 1.6040\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0566 - mse: 5.0566 - mae: 1.6239 - val_loss: 4.9525 - val_mse: 4.9525 - val_mae: 1.8001\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0901 - mse: 5.0901 - mae: 1.6281 - val_loss: 4.3893 - val_mse: 4.3893 - val_mae: 1.7279\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3867 - mse: 5.3867 - mae: 1.6983 - val_loss: 5.1902 - val_mse: 5.1902 - val_mae: 1.8340\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1751 - mse: 5.1751 - mae: 1.6495 - val_loss: 4.4765 - val_mse: 4.4765 - val_mae: 1.7133\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1228 - mse: 5.1228 - mae: 1.6473 - val_loss: 4.5339 - val_mse: 4.5339 - val_mae: 1.7271\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1896 - mse: 5.1896 - mae: 1.6405 - val_loss: 4.3854 - val_mse: 4.3854 - val_mae: 1.6893\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3075 - mse: 5.3075 - mae: 1.6738 - val_loss: 4.6711 - val_mse: 4.6711 - val_mae: 1.7421\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2569 - mse: 5.2569 - mae: 1.6726 - val_loss: 4.6752 - val_mse: 4.6752 - val_mae: 1.7529\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2483 - mse: 5.2483 - mae: 1.6542 - val_loss: 5.2612 - val_mse: 5.2612 - val_mae: 1.8636\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0722 - mse: 5.0722 - mae: 1.6410 - val_loss: 4.3574 - val_mse: 4.3574 - val_mae: 1.6910\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3691 - mse: 5.3691 - mae: 1.6754 - val_loss: 4.1826 - val_mse: 4.1826 - val_mae: 1.6488\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0248 - mse: 5.0248 - mae: 1.6269 - val_loss: 4.8614 - val_mse: 4.8614 - val_mae: 1.7776\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0805 - mse: 5.0805 - mae: 1.6510 - val_loss: 4.1493 - val_mse: 4.1493 - val_mae: 1.6448\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0155 - mse: 5.0155 - mae: 1.6366 - val_loss: 4.3912 - val_mse: 4.3912 - val_mae: 1.7344\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0927 - mse: 5.0927 - mae: 1.6314 - val_loss: 4.1982 - val_mse: 4.1982 - val_mae: 1.6449\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3147 - mse: 5.3147 - mae: 1.6701 - val_loss: 4.2565 - val_mse: 4.2565 - val_mae: 1.6799\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.3619 - mse: 5.3619 - mae: 1.6868 - val_loss: 5.1217 - val_mse: 5.1217 - val_mae: 1.8302\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.2908 - mse: 5.2908 - mae: 1.6467 - val_loss: 4.2286 - val_mse: 4.2286 - val_mae: 1.6697\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0422 - mse: 5.0422 - mae: 1.6413 - val_loss: 4.0775 - val_mse: 4.0775 - val_mae: 1.6197\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2605 - mse: 5.2605 - mae: 1.6472 - val_loss: 4.2176 - val_mse: 4.2176 - val_mae: 1.6696\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3108 - mse: 5.3108 - mae: 1.6632 - val_loss: 4.1483 - val_mse: 4.1483 - val_mae: 1.6422\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2190 - mse: 5.2190 - mae: 1.6597 - val_loss: 4.9958 - val_mse: 4.9958 - val_mae: 1.8240\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.1071 - mse: 5.1071 - mae: 1.6184 - val_loss: 4.3060 - val_mse: 4.3060 - val_mae: 1.7104\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0294 - mse: 5.0294 - mae: 1.6351 - val_loss: 4.5457 - val_mse: 4.5457 - val_mae: 1.7106\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0797 - mse: 5.0797 - mae: 1.6084 - val_loss: 4.1006 - val_mse: 4.1006 - val_mae: 1.6287\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0572 - mse: 5.0572 - mae: 1.6168 - val_loss: 4.3717 - val_mse: 4.3717 - val_mae: 1.7314\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1663 - mse: 5.1663 - mae: 1.6557 - val_loss: 4.3369 - val_mse: 4.3369 - val_mae: 1.7006\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2181 - mse: 5.2181 - mae: 1.6358 - val_loss: 4.1455 - val_mse: 4.1455 - val_mae: 1.6350\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2270 - mse: 5.2270 - mae: 1.6704 - val_loss: 4.1432 - val_mse: 4.1432 - val_mae: 1.6435\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1958 - mse: 5.1958 - mae: 1.6405 - val_loss: 4.5058 - val_mse: 4.5058 - val_mae: 1.7137\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0230 - mse: 5.0230 - mae: 1.6330 - val_loss: 4.5903 - val_mse: 4.5903 - val_mae: 1.7283\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3489 - mse: 5.3489 - mae: 1.7063 - val_loss: 4.3113 - val_mse: 4.3113 - val_mae: 1.6919\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1772 - mse: 5.1772 - mae: 1.6632 - val_loss: 4.2415 - val_mse: 4.2415 - val_mae: 1.6727\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0258 - mse: 5.0258 - mae: 1.6207 - val_loss: 4.2211 - val_mse: 4.2211 - val_mae: 1.6652\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.3738 - mse: 5.3738 - mae: 1.6894 - val_loss: 4.3170 - val_mse: 4.3170 - val_mae: 1.7030\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2712 - mse: 5.2712 - mae: 1.6707 - val_loss: 4.4089 - val_mse: 4.4089 - val_mae: 1.7024\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0786 - mse: 5.0786 - mae: 1.6240 - val_loss: 4.5143 - val_mse: 4.5143 - val_mae: 1.7313\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1538 - mse: 5.1538 - mae: 1.6405 - val_loss: 4.4068 - val_mse: 4.4068 - val_mae: 1.6966\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9624 - mse: 4.9624 - mae: 1.6150 - val_loss: 4.5459 - val_mse: 4.5459 - val_mae: 1.7205\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1286 - mse: 5.1286 - mae: 1.6528 - val_loss: 4.2721 - val_mse: 4.2721 - val_mae: 1.6647\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5612 - mse: 5.5612 - mae: 1.7054 - val_loss: 4.4569 - val_mse: 4.4569 - val_mae: 1.7373\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0939 - mse: 5.0939 - mae: 1.6340 - val_loss: 4.1974 - val_mse: 4.1974 - val_mae: 1.6630\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1624 - mse: 5.1624 - mae: 1.6414 - val_loss: 4.2142 - val_mse: 4.2142 - val_mae: 1.6621\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9692 - mse: 4.9692 - mae: 1.5841 - val_loss: 4.4954 - val_mse: 4.4954 - val_mae: 1.6979\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1823 - mse: 5.1823 - mae: 1.6413 - val_loss: 4.4403 - val_mse: 4.4403 - val_mae: 1.6992\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2131 - mse: 5.2131 - mae: 1.6133 - val_loss: 4.4671 - val_mse: 4.4671 - val_mae: 1.7068\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1951 - mse: 5.1951 - mae: 1.7067 - val_loss: 4.1861 - val_mse: 4.1861 - val_mae: 1.6589\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9549 - mse: 4.9549 - mae: 1.6196 - val_loss: 4.3798 - val_mse: 4.3798 - val_mae: 1.6890\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9242 - mse: 4.9242 - mae: 1.5965 - val_loss: 4.3591 - val_mse: 4.3591 - val_mae: 1.6919\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1881 - mse: 5.1881 - mae: 1.6499 - val_loss: 4.3028 - val_mse: 4.3028 - val_mae: 1.6650\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.4453 - mse: 5.4453 - mae: 1.6778 - val_loss: 4.1900 - val_mse: 4.1900 - val_mae: 1.6652\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0624 - mse: 5.0624 - mae: 1.6123 - val_loss: 4.2958 - val_mse: 4.2958 - val_mae: 1.6868\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9080 - mse: 4.9080 - mae: 1.6202 - val_loss: 4.7613 - val_mse: 4.7613 - val_mae: 1.7571\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3027 - mse: 5.3027 - mae: 1.6946 - val_loss: 4.1619 - val_mse: 4.1619 - val_mae: 1.6505\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1156 - mse: 5.1156 - mae: 1.6292 - val_loss: 4.9005 - val_mse: 4.9005 - val_mae: 1.7916\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.3567 - mse: 5.3567 - mae: 1.6731 - val_loss: 4.5694 - val_mse: 4.5694 - val_mae: 1.7264\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9766 - mse: 4.9766 - mae: 1.6088 - val_loss: 4.1300 - val_mse: 4.1300 - val_mae: 1.6469\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.9887 - mse: 4.9887 - mae: 1.5959 - val_loss: 4.5980 - val_mse: 4.5980 - val_mae: 1.7317\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 4.8915 - mse: 4.8915 - mae: 1.6165 - val_loss: 4.1704 - val_mse: 4.1704 - val_mae: 1.6436\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.0920 - mse: 5.0920 - mae: 1.6327 - val_loss: 4.5043 - val_mse: 4.5043 - val_mae: 1.7000\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.2524 - mse: 5.2524 - mae: 1.6617 - val_loss: 4.3231 - val_mse: 4.3231 - val_mae: 1.6910\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.0545 - mse: 5.0545 - mae: 1.6288 - val_loss: 4.1806 - val_mse: 4.1806 - val_mae: 1.6445\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 5.1625 - mse: 5.1625 - mae: 1.6359 - val_loss: 4.1486 - val_mse: 4.1486 - val_mae: 1.6443\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9739 - mse: 4.9739 - mae: 1.6249 - val_loss: 4.0741 - val_mse: 4.0741 - val_mae: 1.6215\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0637 - mse: 5.0637 - mae: 1.6398 - val_loss: 4.1916 - val_mse: 4.1916 - val_mae: 1.6624\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.0379 - mse: 5.0379 - mae: 1.6101 - val_loss: 4.2312 - val_mse: 4.2312 - val_mae: 1.6515\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9366 - mse: 4.9366 - mae: 1.6196 - val_loss: 4.1619 - val_mse: 4.1619 - val_mae: 1.6385\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1604 - mse: 5.1604 - mae: 1.6904 - val_loss: 4.4423 - val_mse: 4.4423 - val_mae: 1.7034\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0758 - mse: 5.0758 - mae: 1.6247 - val_loss: 4.3308 - val_mse: 4.3308 - val_mae: 1.6923\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9531 - mse: 4.9531 - mae: 1.6121 - val_loss: 4.1917 - val_mse: 4.1917 - val_mae: 1.6475\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.0303 - mse: 5.0303 - mae: 1.5923 - val_loss: 4.1841 - val_mse: 4.1841 - val_mae: 1.6507\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1302 - mse: 5.1302 - mae: 1.6587 - val_loss: 4.3128 - val_mse: 4.3128 - val_mae: 1.6826\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9654 - mse: 4.9654 - mae: 1.6171 - val_loss: 4.7386 - val_mse: 4.7386 - val_mae: 1.7613\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9735 - mse: 4.9735 - mae: 1.6200 - val_loss: 4.5050 - val_mse: 4.5050 - val_mae: 1.7096\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3832 - mse: 5.3832 - mae: 1.6778 - val_loss: 4.6284 - val_mse: 4.6284 - val_mae: 1.7365\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8962 - mse: 4.8962 - mae: 1.5976 - val_loss: 4.0835 - val_mse: 4.0835 - val_mae: 1.6264\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0247 - mse: 5.0247 - mae: 1.6121 - val_loss: 4.4146 - val_mse: 4.4146 - val_mae: 1.6950\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0537 - mse: 5.0537 - mae: 1.6426 - val_loss: 4.8008 - val_mse: 4.8008 - val_mae: 1.7729\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1038 - mse: 5.1038 - mae: 1.6193 - val_loss: 6.3667 - val_mse: 6.3667 - val_mae: 2.0752\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2960 - mse: 5.2960 - mae: 1.7010 - val_loss: 4.2248 - val_mse: 4.2248 - val_mae: 1.6627\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9718 - mse: 4.9718 - mae: 1.6011 - val_loss: 4.2204 - val_mse: 4.2204 - val_mae: 1.6747\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.8796 - mse: 4.8796 - mae: 1.6005 - val_loss: 4.2424 - val_mse: 4.2424 - val_mae: 1.6614\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1099 - mse: 5.1099 - mae: 1.6472 - val_loss: 4.2147 - val_mse: 4.2147 - val_mae: 1.6812\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9174 - mse: 4.9174 - mae: 1.6007 - val_loss: 4.7130 - val_mse: 4.7130 - val_mae: 1.7588\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1292 - mse: 5.1292 - mae: 1.6512 - val_loss: 4.2483 - val_mse: 4.2483 - val_mae: 1.6877\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9649 - mse: 4.9649 - mae: 1.6166 - val_loss: 4.1707 - val_mse: 4.1707 - val_mae: 1.6408\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.8385 - mse: 4.8385 - mae: 1.6274 - val_loss: 4.0864 - val_mse: 4.0864 - val_mae: 1.6210\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9408 - mse: 4.9408 - mae: 1.6151 - val_loss: 4.1033 - val_mse: 4.1033 - val_mae: 1.6266\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1544 - mse: 5.1544 - mae: 1.6576 - val_loss: 4.8980 - val_mse: 4.8980 - val_mae: 1.7933\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9627 - mse: 4.9627 - mae: 1.6373 - val_loss: 4.1550 - val_mse: 4.1550 - val_mae: 1.6446\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0737 - mse: 5.0737 - mae: 1.6584 - val_loss: 4.3442 - val_mse: 4.3442 - val_mae: 1.6770\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3046 - mse: 5.3046 - mae: 1.6665 - val_loss: 4.3020 - val_mse: 4.3020 - val_mae: 1.6756\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9757 - mse: 4.9757 - mae: 1.6414 - val_loss: 4.3612 - val_mse: 4.3612 - val_mae: 1.6842\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1080 - mse: 5.1080 - mae: 1.6159 - val_loss: 4.3078 - val_mse: 4.3078 - val_mae: 1.6765\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8194 - mse: 4.8194 - mae: 1.6029 - val_loss: 4.0664 - val_mse: 4.0664 - val_mae: 1.6212\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8080 - mse: 4.8080 - mae: 1.5824 - val_loss: 4.0842 - val_mse: 4.0842 - val_mae: 1.6275\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.8284 - mse: 4.8284 - mae: 1.5892 - val_loss: 4.0533 - val_mse: 4.0533 - val_mae: 1.6108\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1369 - mse: 5.1369 - mae: 1.6497 - val_loss: 4.3650 - val_mse: 4.3650 - val_mae: 1.6832\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0965 - mse: 5.0965 - mae: 1.6291 - val_loss: 4.2402 - val_mse: 4.2402 - val_mae: 1.6559\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.8501 - mse: 4.8501 - mae: 1.5923 - val_loss: 4.5159 - val_mse: 4.5159 - val_mae: 1.7207\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0461 - mse: 5.0461 - mae: 1.5827 - val_loss: 4.3789 - val_mse: 4.3789 - val_mae: 1.6920\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9484 - mse: 4.9484 - mae: 1.6100 - val_loss: 4.5416 - val_mse: 4.5416 - val_mae: 1.7366\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.0164 - mse: 5.0164 - mae: 1.6194 - val_loss: 5.2733 - val_mse: 5.2733 - val_mae: 1.8643\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.8248 - mse: 4.8248 - mae: 1.5885 - val_loss: 4.8309 - val_mse: 4.8309 - val_mae: 1.7694\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.0509 - mse: 5.0509 - mae: 1.6264 - val_loss: 4.4814 - val_mse: 4.4814 - val_mae: 1.7098\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1199 - mse: 5.1199 - mae: 1.6462 - val_loss: 4.9142 - val_mse: 4.9142 - val_mae: 1.8018\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.9167 - mse: 4.9167 - mae: 1.6193 - val_loss: 4.2744 - val_mse: 4.2744 - val_mae: 1.6656\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.8755 - mse: 4.8755 - mae: 1.5992 - val_loss: 4.1955 - val_mse: 4.1955 - val_mae: 1.6655\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0045 - mse: 5.0045 - mae: 1.6385 - val_loss: 4.0926 - val_mse: 4.0926 - val_mae: 1.6270\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0634 - mse: 5.0634 - mae: 1.6310 - val_loss: 4.1515 - val_mse: 4.1515 - val_mae: 1.6491\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.8900 - mse: 4.8900 - mae: 1.5895 - val_loss: 4.3227 - val_mse: 4.3227 - val_mae: 1.6759\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9156 - mse: 4.9156 - mae: 1.6194 - val_loss: 4.2949 - val_mse: 4.2949 - val_mae: 1.6954\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.7849 - mse: 4.7849 - mae: 1.5696 - val_loss: 4.4841 - val_mse: 4.4841 - val_mae: 1.7125\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8803 - mse: 4.8803 - mae: 1.6131 - val_loss: 4.2908 - val_mse: 4.2908 - val_mae: 1.6856\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9268 - mse: 4.9268 - mae: 1.6212 - val_loss: 5.1200 - val_mse: 5.1200 - val_mae: 1.8470\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1148 - mse: 5.1148 - mae: 1.6255 - val_loss: 4.4040 - val_mse: 4.4040 - val_mae: 1.6963\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7352 - mse: 4.7352 - mae: 1.5752 - val_loss: 4.2134 - val_mse: 4.2134 - val_mae: 1.6733\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.8475 - mse: 4.8475 - mae: 1.6151 - val_loss: 5.2495 - val_mse: 5.2495 - val_mae: 1.8839\n",
            "Epoch 947/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 4.1816 - mse: 4.1816 - mae: 1.5240"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "YI960pqpyuCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n-B8HFk-yt_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## validation ############"
      ],
      "metadata": {
        "id": "CYQd6iu3fr43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed1PScklVvKg"
      },
      "source": [
        "## epoch_history 객체에 저장된 통계치를 사용해 모델의 훈련 과정을 시각화!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVZna3oNcLzn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history) :\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure(figsize = (8, 12))\n",
        "\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.xlabel('Eopoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mae'], label = 'Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.xlabel('Eopoch')\n",
        "  plt.ylabel('Mean Squared Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mse'], label = 'Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOpXkOj0cLu_"
      },
      "source": [
        "plot_history(epoch_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8mBgspbcLrY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSRcQZ6VvEG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSp0L11saPAv"
      },
      "source": [
        "이 그래프를 보면 수 백번 에포크를 진행한 이후에는 모델이 거의 향상되지 않는 것 같습니다. model.fit 메서드를 수정하여 검증 점수가 향상되지 않으면 자동으로 훈련을 멈추도록 만들어 보죠. 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 콜백(callback)을 사용하겠습니다. 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
        "\n",
        "이 콜백에 대해 더 자세한 내용은 여기를 참고하세요.[링크 텍스트](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQKHNKRkVu0G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Iuc9sEfVuw4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbHt_eP6Vut4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbzDASkqVuq3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm3d4rOiVun2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfIQ6qlcVukv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heTZlv6_Vuh2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aws_3CpwVkav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U87cAx8bVkXn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs2B_2I1VkUu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUVsFDOqVkRv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l__XYQXyVkO2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyTOI9D9CHJS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQk4QslICHGT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}